{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNsFVUcQAqVlIRJHy4k+9AT"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# GPT-2 from Scratch\n",
        "\n",
        "<!-- Welcome to this comprehensive tutorial on building GPT-2 from scratch! This notebook is optimized for **GPU**.\n",
        "\n",
        "## What You'll Build:\n",
        "- Complete GPT-2 architecture from scratch\n",
        "- Working text generation model\n",
        "- All components explained step-by-step\n",
        "- Memory-optimized for GPU (~15GB VRAM) -->\n",
        "\n",
        "## Table of Contents\n",
        "- [Environment Setup](#environment-setup)\n",
        "- [Architecture Overview](#architecture-overview)\n",
        "- [Token Embeddings](#token-embeddings)\n",
        "- [Positional Encodings](#positional-encodings)\n",
        "- [Multi-Head Self-Attention](#multi-head-self-attention)\n",
        "- [Causal Masking](#causal-masking)\n",
        "- [Feed-Forward Networks](#feed-forward-networks)\n",
        "- [Transformer Block](#transformer-block)\n",
        "- [Complete GPT-2 Model](#complete-gpt-2-model)\n",
        "- [Text Generation](#text-generation)\n",
        "- [Training Demo](#training-demo)\n",
        "- [Performance Testing](#performance-testing)"
      ],
      "metadata": {
        "id": "gJ1BfTtRnkfW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nxci7__bmvd2",
        "outputId": "6f607863-6537-44be-ce95-b504a3d286e5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "GPU: Tesla T4\n",
            "GPU Memory: 15.8 GB\n"
          ]
        }
      ],
      "source": [
        "# Environment Setup\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import math\n",
        "import numpy as np\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "# Check GPU availability\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    gpu_name = torch.cuda.get_device_name(0)\n",
        "    gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1e9\n",
        "    print(f\"GPU: {gpu_name}\")\n",
        "    print(f\"GPU Memory: {gpu_memory:.1f} GB\")\n",
        "\n",
        "    # Enable optimizations for T4\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "    torch.cuda.empty_cache()\n",
        "else:\n",
        "    print(\"GPU not available. Switch to GPU runtime!\")\n",
        "\n",
        "# Set seeds for reproducibility\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed(42)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Architecture Overview\n",
        "\n",
        "GPT-2 is a **decoder-only transformer** that predicts the next token in a sequence.\n",
        "\n",
        "### Key Components:\n",
        "1. **Token Embeddings** + **Positional Encodings**\n",
        "2. **Multi-Head Self-Attention** with causal masking\n",
        "3. **Feed-Forward Networks** with GELU activation\n",
        "4. **Layer Normalization** (pre-norm style)\n",
        "5. **Language Modeling Head** for token prediction\n",
        "\n",
        "### GPU Considerations:\n",
        "- **Memory**: ~15GB VRAM allows GPT-2 Small/Medium training\n",
        "- **Compute**: Good for inference, moderate for training\n",
        "- **Optimization**: We'll use mixed precision and gradient checkpointing"
      ],
      "metadata": {
        "id": "0ARw2D1Ln4B6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Memory and Performance Utilities\n",
        "def get_model_size(model):\n",
        "    \"\"\"Calculate model size in parameters and memory.\"\"\"\n",
        "    param_count = sum(p.numel() for p in model.parameters())\n",
        "    param_size = sum(p.numel() * p.element_size() for p in model.parameters())\n",
        "    buffer_size = sum(b.numel() * b.element_size() for b in model.buffers())\n",
        "    total_size = param_size + buffer_size\n",
        "\n",
        "    return {\n",
        "        'parameters': param_count,\n",
        "        'size_mb': total_size / 1e6,\n",
        "        'size_gb': total_size / 1e9\n",
        "    }\n",
        "\n",
        "def check_gpu_memory():\n",
        "    \"\"\"Check GPU memory usage.\"\"\"\n",
        "    if torch.cuda.is_available():\n",
        "        allocated = torch.cuda.memory_allocated() / 1e9\n",
        "        cached = torch.cuda.memory_reserved() / 1e9\n",
        "        total = torch.cuda.get_device_properties(0).total_memory / 1e9\n",
        "        print(f\"GPU Memory - Allocated: {allocated:.1f}GB, Cached: {cached:.1f}GB, Total: {total:.1f}GB\")\n",
        "        return allocated, cached, total\n",
        "    return 0, 0, 0\n",
        "\n",
        "# Initial memory check\n",
        "check_gpu_memory()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ag3e3_i7ntY3",
        "outputId": "968ff96d-30ea-460c-e3fe-346d07d6f55b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU Memory - Allocated: 0.0GB, Cached: 0.0GB, Total: 15.8GB\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.0, 0.0, 15.828320256)"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Token Embeddings\n",
        "\n",
        "Convert discrete tokens to dense vectors that the model can work with.\n",
        "\n",
        "### Key Points:\n",
        "- Each token gets a learnable vector of size `d_model`\n",
        "- Scaled by √d_model for better training dynamics\n",
        "- Shared with output layer (weight tying) to save memory"
      ],
      "metadata": {
        "id": "fPYMMsxBoJmc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TokenEmbedding(nn.Module):\n",
        "    \"\"\"\n",
        "    Token embedding layer optimized for memory efficiency.\n",
        "    \"\"\"\n",
        "    def __init__(self, vocab_size, d_model):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, d_model)\n",
        "        self.d_model = d_model\n",
        "\n",
        "        # Initialize weights (important for training stability)\n",
        "        nn.init.normal_(self.embedding.weight, mean=0, std=0.02)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Scale by sqrt(d_model) as in original paper\n",
        "        return self.embedding(x) * math.sqrt(self.d_model)\n",
        "\n",
        "# Test token embeddings\n",
        "vocab_size = 50257  # GPT-2 vocabulary\n",
        "d_model = 768       # GPT-2 small dimension\n",
        "\n",
        "token_embed = TokenEmbedding(vocab_size, d_model).to(device)\n",
        "test_tokens = torch.randint(0, vocab_size, (2, 10)).to(device)\n",
        "embedded = token_embed(test_tokens)\n",
        "\n",
        "print(f\"Token Embedding Test:\")\n",
        "print(f\"Input: {test_tokens.shape} -> Output: {embedded.shape}\")\n",
        "print(f\"Memory: {get_model_size(token_embed)['size_mb']:.1f}MB\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9xRngbHEoGuk",
        "outputId": "dcc08040-9e76-4459-c4fe-429e5e5acd16"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token Embedding Test:\n",
            "Input: torch.Size([2, 10]) -> Output: torch.Size([2, 10, 768])\n",
            "Memory: 154.4MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Positional Encodings\n",
        "\n",
        "GPT-2 uses **learned positional embeddings** to give the model information about token positions.\n",
        "\n",
        "### Why This Matters:\n",
        "- \"The cat sat on the mat\" ≠ \"The mat sat on the cat\"\n",
        "- Transformers have no built-in sense of order\n",
        "- Learned embeddings adapt to the specific task"
      ],
      "metadata": {
        "id": "CsmE5tLooYSD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PositionalEncoding(nn.Module):\n",
        "    \"\"\"\n",
        "    Learnable positional embeddings for GPT-2.\n",
        "    \"\"\"\n",
        "    def __init__(self, max_seq_len, d_model):\n",
        "        super().__init__()\n",
        "        self.pos_embedding = nn.Embedding(max_seq_len, d_model)\n",
        "\n",
        "        # Initialize positional embeddings\n",
        "        nn.init.normal_(self.pos_embedding.weight, mean=0, std=0.02)\n",
        "\n",
        "    def forward(self, x):\n",
        "        seq_len = x.size(1)\n",
        "        positions = torch.arange(0, seq_len, device=x.device)\n",
        "        return self.pos_embedding(positions)\n",
        "\n",
        "# Test positional encodings\n",
        "max_seq_len = 1024\n",
        "pos_encoding = PositionalEncoding(max_seq_len, d_model).to(device)\n",
        "\n",
        "seq_len = 10\n",
        "test_input = torch.randn(2, seq_len, d_model).to(device)\n",
        "pos_emb = pos_encoding(test_input)\n",
        "combined = test_input + pos_emb\n",
        "\n",
        "print(f\"Positional Encoding Test:\")\n",
        "print(f\"Input: {test_input.shape}\")\n",
        "print(f\"Pos embeddings: {pos_emb.shape}\")\n",
        "print(f\"Combined: {combined.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ztCxFZj_oPMI",
        "outputId": "53310202-8a42-448e-eedd-8ef053309726"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Positional Encoding Test:\n",
            "Input: torch.Size([2, 10, 768])\n",
            "Pos embeddings: torch.Size([10, 768])\n",
            "Combined: torch.Size([2, 10, 768])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Multi-Head Self-Attention\n",
        "\n",
        "The **heart of the transformer**! Allows the model to focus on different parts of the sequence simultaneously.\n",
        "\n",
        "### Key Concepts:\n",
        "- **Query (Q)**: \"What am I looking for?\"\n",
        "- **Key (K)**: \"What information do I have?\"\n",
        "- **Value (V)**: \"What information do I provide?\"\n",
        "- **Multiple heads**: Parallel attention patterns\n",
        "\n",
        "### Formula:\n",
        "$$\\text{Attention}(Q, K, V) = \\text{softmax}\\left(\\frac{QK^T}{\\sqrt{d_k}}\\right)V$$\n",
        "  where:\n",
        "  - $d_k$: The dimension of the keys (used as the scaling factor)"
      ],
      "metadata": {
        "id": "J8wI96iAo7J7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### T4 Optimization:\n",
        "- Using `F.scaled_dot_product_attention()` (PyTorch 2.0+) for memory efficiency"
      ],
      "metadata": {
        "id": "OrnJvHmAp-et"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiHeadAttention(nn.Module):\n",
        "    \"\"\"\n",
        "    Multi-Head Self-Attention optimized for T4 GPU.\n",
        "    \"\"\"\n",
        "    def __init__(self, d_model, n_heads, dropout=0.1):\n",
        "        super().__init__()\n",
        "        assert d_model % n_heads == 0\n",
        "\n",
        "        self.d_model = d_model\n",
        "        self.n_heads = n_heads\n",
        "        self.d_k = d_model // n_heads\n",
        "\n",
        "        # Combined QKV projection for efficiency\n",
        "        self.qkv_proj = nn.Linear(d_model, 3 * d_model, bias=False)\n",
        "        self.out_proj = nn.Linear(d_model, d_model, bias=False)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "        # Initialize weights\n",
        "        nn.init.normal_(self.qkv_proj.weight, mean=0, std=0.02)\n",
        "        nn.init.normal_(self.out_proj.weight, mean=0, std=0.02)\n",
        "\n",
        "    def forward(self, x, mask=None):\n",
        "        batch_size, seq_len, d_model = x.shape\n",
        "\n",
        "        # Single projection for Q, K, V\n",
        "        qkv = self.qkv_proj(x)  # (B, L, 3*d_model)\n",
        "        qkv = qkv.reshape(batch_size, seq_len, 3, self.n_heads, self.d_k)\n",
        "        qkv = qkv.permute(2, 0, 3, 1, 4)  # (3, B, n_heads, L, d_k)\n",
        "        q, k, v = qkv[0], qkv[1], qkv[2]\n",
        "\n",
        "        # Scaled dot-product attention (optimized for PyTorch 2.0+)\n",
        "        if hasattr(F, 'scaled_dot_product_attention'):\n",
        "            # Use PyTorch's optimized attention (faster on modern GPUs)\n",
        "            attn_output = F.scaled_dot_product_attention(\n",
        "                q, k, v, attn_mask=mask, dropout_p=self.dropout.p if self.training else 0\n",
        "            )\n",
        "        else:\n",
        "            # Fallback implementation\n",
        "            scores = torch.matmul(q, k.transpose(-2, -1)) / math.sqrt(self.d_k)\n",
        "            if mask is not None:\n",
        "                scores = scores.masked_fill(mask == 0, -1e9)\n",
        "            attn_weights = F.softmax(scores, dim=-1)\n",
        "            attn_weights = self.dropout(attn_weights)\n",
        "            attn_output = torch.matmul(attn_weights, v)\n",
        "\n",
        "        # Reshape and project output\n",
        "        attn_output = attn_output.transpose(1, 2).contiguous()\n",
        "        attn_output = attn_output.reshape(batch_size, seq_len, d_model)\n",
        "        output = self.out_proj(attn_output)\n",
        "\n",
        "        return output\n",
        "\n",
        "# Test multi-head attention\n",
        "n_heads = 12\n",
        "attention = MultiHeadAttention(d_model, n_heads).to(device)\n",
        "\n",
        "test_input = torch.randn(2, 10, d_model).to(device)\n",
        "attn_output = attention(test_input)\n",
        "\n",
        "print(f\"Multi-Head Attention Test:\")\n",
        "print(f\"Input: {test_input.shape} -> Output: {attn_output.shape}\")\n",
        "print(f\"Parameters: {sum(p.numel() for p in attention.parameters()):,}\")\n",
        "\n",
        "# Memory check\n",
        "check_gpu_memory()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "705aT_7kozyK",
        "outputId": "4b6627ba-2acd-4aee-f40b-07f14e97f4b4"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Multi-Head Attention Test:\n",
            "Input: torch.Size([2, 10, 768]) -> Output: torch.Size([2, 10, 768])\n",
            "Parameters: 2,359,296\n",
            "GPU Memory - Allocated: 0.2GB, Cached: 0.3GB, Total: 15.8GB\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.177604608, 0.312475648, 15.828320256)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "## Causal Masking (Look-Ahead Masking)\n",
        "\n",
        "Causal Masking is a technique used exclusively in the **decoder** of the Transformer (and in decoder-only models like GPT) to ensure the model remains **autoregressive**, (preventing it from \"looking forward\").\n",
        "\n",
        "### Why It's Critical:\n",
        "\n",
        "* **Training**: The model learns to predict the next token $\\mathbf{y}_t$ based only on previous tokens $\\mathbf{y}_{<t}$. This prevents \"cheating\" by looking at future answers.\n",
        "* **Generation**: It enforces the sequential, left-to-right generation process.\n",
        "* **Consistency**: It guarantees the same behavior during both training and inference (generation).\n",
        "\n",
        "### Pattern: The Causal Mask Matrix\n",
        "\n",
        "The causal mask creates a **lower triangular matrix**. Positions above the main diagonal are masked, preventing attention flow from future tokens.\n",
        "\n",
        "For a sequence of length $N=4$, the mask looks like this (where $\\mathbf{-\\infty}$ masks the connection):\n",
        "\n",
        "$$\n",
        "\\begin{array}{c|cccc}\n",
        "\\text{To } \\rightarrow & 0 & 1 & 2 & 3 \\\\\n",
        "\\hline\n",
        "\\text{From } 0 & 0 & \\mathbf{-\\infty} & \\mathbf{-\\infty} & \\mathbf{-\\infty} \\\\\n",
        "\\text{From } 1 & 0 & 0 & \\mathbf{-\\infty} & \\mathbf{-\\infty} \\\\\n",
        "\\text{From } 2 & 0 & 0 & 0 & \\mathbf{-\\infty} \\\\\n",
        "\\text{From } 3 & 0 & 0 & 0 & 0\n",
        "\\end{array}\n",
        "$$\n",
        "\n",
        "**Effect:** Masked values ($\\mathbf{-\\infty}$) become **zero** after the $\\text{softmax}$ operation, effectively disconnecting the query from future keys/values."
      ],
      "metadata": {
        "id": "Thp1pRDtqJkh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_causal_mask(seq_len, device=None):\n",
        "    \"\"\"\n",
        "    Create causal attention mask (lower triangular).\n",
        "    \"\"\"\n",
        "    mask = torch.tril(torch.ones(seq_len, seq_len, device=device))\n",
        "    return mask.unsqueeze(0).unsqueeze(0)  # Add batch and head dimensions\n",
        "\n",
        "# Test causal masking\n",
        "seq_len = 8\n",
        "mask = create_causal_mask(seq_len, device)\n",
        "print(f\"Causal Mask Test (seq_len={seq_len}):\")\n",
        "print(mask.squeeze().int())\n",
        "\n",
        "# Visualize the mask\n",
        "plt.figure(figsize=(6, 5))\n",
        "plt.imshow(mask.squeeze().cpu(), cmap='Blues')\n",
        "plt.title('Causal Attention Mask')\n",
        "plt.xlabel('Key Position')\n",
        "plt.ylabel('Query Position')\n",
        "plt.colorbar()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 635
        },
        "id": "FHpyQGI-qESA",
        "outputId": "0731d7da-031c-4a2d-e580-981ebfc9528d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Causal Mask Test (seq_len=8):\n",
            "tensor([[1, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0', dtype=torch.int32)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x500 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Feed-Forward Networks\n",
        "\n",
        "Position-wise feed-forward network that processes the attention output.\n",
        "\n",
        "### Architecture:\n",
        "1. **Expand**: $$ d_{model} → 4×d_{model}  $$\n",
        "<br>\n",
        "\n",
        "2. **Activate**: GELU (smoother than ReLU)\n",
        "\n",
        "<br>\n",
        "\n",
        "3. **Contract**: $$ 4×d_{model} → d_{model} $$\n",
        "\n",
        "### GELU Benefits:\n",
        "- Smoother gradients than ReLU\n",
        "- Better performance on language tasks\n",
        "- Used in most modern transformers"
      ],
      "metadata": {
        "id": "6XTCdBFirqjV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class FeedForward(nn.Module):\n",
        "    \"\"\"\n",
        "    Position-wise feed-forward network with GELU activation.\n",
        "    \"\"\"\n",
        "    def __init__(self, d_model, d_ff=None, dropout=0.1):\n",
        "        super().__init__()\n",
        "        if d_ff is None:\n",
        "            d_ff = 4 * d_model\n",
        "\n",
        "        self.linear1 = nn.Linear(d_model, d_ff)\n",
        "        self.linear2 = nn.Linear(d_ff, d_model)\n",
        "        self.gelu = nn.GELU()\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "        # Initialize weights\n",
        "        nn.init.normal_(self.linear1.weight, mean=0, std=0.02)\n",
        "        nn.init.normal_(self.linear2.weight, mean=0, std=0.02)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.linear1(x)\n",
        "        x = self.gelu(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.linear2(x)\n",
        "        return x\n",
        "\n",
        "# Test feed-forward network\n",
        "d_ff = 4 * d_model  # Standard 4x expansion\n",
        "ff_network = FeedForward(d_model, d_ff).to(device)\n",
        "\n",
        "test_input = torch.randn(2, 10, d_model).to(device)\n",
        "ff_output = ff_network(test_input)\n",
        "\n",
        "print(f\"Feed-Forward Test:\")\n",
        "print(f\"Input: {test_input.shape} -> Output: {ff_output.shape}\")\n",
        "print(f\"Expansion ratio: {d_ff // d_model}x\")\n",
        "print(f\"Parameters: {sum(p.numel() for p in ff_network.parameters()):,}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SPtUA3cnqZEh",
        "outputId": "78fd2fc5-b860-4a1f-991f-ec10296e33e1"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feed-Forward Test:\n",
            "Input: torch.Size([2, 10, 768]) -> Output: torch.Size([2, 10, 768])\n",
            "Expansion ratio: 4x\n",
            "Parameters: 4,722,432\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The Transformer Block\n",
        "\n",
        "A fundamental unit that combines a self-attention mechanism and a position-wise feed-forward network (FFN), integrated with residual connections and layer normalization.\n",
        "\n",
        "---\n",
        "\n",
        "### GPT-2 Architecture (Pre-LayerNorm)\n",
        "\n",
        "The GPT-style architecture uses **Layer Normalization** *before* the attention and feed-forward sub-layers (Pre-LayerNorm).\n",
        "\n",
        "* **Pre-LayerNorm**: Applying normalization before the sub-layer inputs stabilizes training.\n",
        "* **Residual Connections** ($\\mathbf{x} + \\text{Sublayer}(\\mathbf{x})$): Crucial for allowing gradients to flow directly through the identity mapping, enabling the training of very deep networks.\n",
        "* **Stability**: This architecture is often more stable, especially in deep models, compared to the original \"Post-LayerNorm\" design (like in the original BERT/Transformer paper).\n",
        "\n",
        "---\n",
        "\n",
        "### Data Flow Diagram\n",
        "\n",
        "The process involves two main steps, each combining a sub-layer with a residual connection and a LayerNorm:\n",
        "\n",
        "$$\n",
        "\\mathbf{h} = \\mathbf{x} + \\text{Attention}(\\text{LayerNorm}(\\mathbf{x}))\n",
        "$$\n",
        "\n",
        "$$\n",
        "\\mathbf{y} = \\mathbf{h} + \\text{FFN}(\\text{LayerNorm}(\\mathbf{h}))\n",
        "$$\n",
        "\n",
        "---\n",
        "\n",
        "### Step-by-Step Flow:\n",
        "\n",
        "The flow shows the input ($\\mathbf{x}$) feeding into a $\\text{LayerNorm}$, then a sub-layer, which is finally added back to the original input ($\\mathbf{x}$ or $\\mathbf{h}$) to form the output.\n"
      ],
      "metadata": {
        "id": "Ulz_K1AksJO5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[![GPT-2 Transformer BLock](https://drive.google.com/uc?export=view&id=1UzS06PQ9PSBd3PhHo4N4NDV9wbRulkv0)](https://drive.google.com/file/d/1UzS06PQ9PSBd3PhHo4N4NDV9wbRulkv0/view?usp=sharing)"
      ],
      "metadata": {
        "id": "vcJb9_4rtWbn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerBlock(nn.Module):\n",
        "    \"\"\"\n",
        "    Single GPT-2 transformer block with pre-layer normalization.\n",
        "    \"\"\"\n",
        "    def __init__(self, d_model, n_heads, d_ff=None, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.attention = MultiHeadAttention(d_model, n_heads, dropout)\n",
        "        self.feed_forward = FeedForward(d_model, d_ff, dropout)\n",
        "        self.ln1 = nn.LayerNorm(d_model)\n",
        "        self.ln2 = nn.LayerNorm(d_model)\n",
        "\n",
        "    def forward(self, x, mask=None):\n",
        "        # Pre-norm attention with residual connection\n",
        "        attn_out = self.attention(self.ln1(x), mask)\n",
        "        x = x + attn_out\n",
        "\n",
        "        # Pre-norm feed-forward with residual connection\n",
        "        ff_out = self.feed_forward(self.ln2(x))\n",
        "        x = x + ff_out\n",
        "\n",
        "        return x\n",
        "\n",
        "# Test transformer block\n",
        "transformer_block = TransformerBlock(d_model, n_heads, d_ff).to(device)\n",
        "\n",
        "test_input = torch.randn(2, 10, d_model).to(device)\n",
        "test_mask = create_causal_mask(10, device)\n",
        "block_output = transformer_block(test_input, test_mask)\n",
        "\n",
        "print(f\"Transformer Block Test:\")\n",
        "print(f\"Input: {test_input.shape} -> Output: {block_output.shape}\")\n",
        "print(f\"Parameters: {sum(p.numel() for p in transformer_block.parameters()):,}\")\n",
        "\n",
        "# Check memory usage\n",
        "check_gpu_memory()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VTEuytlsrutU",
        "outputId": "2248784c-65c7-4e56-a3d7-d3c189a2a810"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transformer Block Test:\n",
            "Input: torch.Size([2, 10, 768]) -> Output: torch.Size([2, 10, 768])\n",
            "Parameters: 7,084,800\n",
            "GPU Memory - Allocated: 0.2GB, Cached: 0.3GB, Total: 15.8GB\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.226622464, 0.316669952, 15.828320256)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Complete GPT-2 Model\n",
        "\n",
        "Now we assemble everything into the full GPT-2 architecture!\n",
        "\n",
        "### Features:\n",
        "- **Memory efficient**: Optimized for T4 GPU\n",
        "- **Weight tying**: Input/output embeddings shared\n",
        "- **Gradient checkpointing**: Optional for larger models\n",
        "- **Mixed precision ready**: For faster training"
      ],
      "metadata": {
        "id": "Bdlrbp03tqVZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GPT2Model(nn.Module):\n",
        "    \"\"\"\n",
        "    Complete GPT-2 model optimized for Google Colab T4.\n",
        "    \"\"\"\n",
        "    def __init__(self, vocab_size, d_model, n_heads, n_layers,\n",
        "                 max_seq_len=1024, dropout=0.1, use_checkpointing=False):\n",
        "        super().__init__()\n",
        "\n",
        "        self.d_model = d_model\n",
        "        self.max_seq_len = max_seq_len\n",
        "        self.use_checkpointing = use_checkpointing\n",
        "\n",
        "        # Embeddings\n",
        "        self.token_embedding = TokenEmbedding(vocab_size, d_model)\n",
        "        self.pos_encoding = PositionalEncoding(max_seq_len, d_model)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "        # Transformer blocks\n",
        "        self.transformer_blocks = nn.ModuleList([\n",
        "            TransformerBlock(d_model, n_heads, 4*d_model, dropout)\n",
        "            for _ in range(n_layers)\n",
        "        ])\n",
        "\n",
        "        # Final layer norm and output head\n",
        "        self.ln_final = nn.LayerNorm(d_model)\n",
        "        self.lm_head = nn.Linear(d_model, vocab_size, bias=False)\n",
        "\n",
        "        # Weight tying (saves memory and often improves performance)\n",
        "        self.lm_head.weight = self.token_embedding.embedding.weight\n",
        "\n",
        "        # Initialize weights\n",
        "        self.apply(self._init_weights)\n",
        "\n",
        "    def _init_weights(self, module):\n",
        "        \"\"\"Initialize weights following GPT-2 paper.\"\"\"\n",
        "        if isinstance(module, nn.Linear):\n",
        "            nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
        "            if module.bias is not None:\n",
        "                nn.init.zeros_(module.bias)\n",
        "        elif isinstance(module, nn.Embedding):\n",
        "            nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
        "        elif isinstance(module, nn.LayerNorm):\n",
        "            nn.init.zeros_(module.bias)\n",
        "            nn.init.ones_(module.weight)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask=None):\n",
        "        batch_size, seq_len = input_ids.shape\n",
        "\n",
        "        # Create causal mask if not provided\n",
        "        if attention_mask is None:\n",
        "            attention_mask = create_causal_mask(seq_len, input_ids.device)\n",
        "\n",
        "        # Embeddings\n",
        "        token_emb = self.token_embedding(input_ids)\n",
        "        pos_emb = self.pos_encoding(token_emb)\n",
        "        x = self.dropout(token_emb + pos_emb)\n",
        "\n",
        "        # Pass through transformer blocks\n",
        "        for block in self.transformer_blocks:\n",
        "            if self.use_checkpointing and self.training:\n",
        "                # Use gradient checkpointing to save memory\n",
        "                x = torch.utils.checkpoint.checkpoint(block, x, attention_mask)\n",
        "            else:\n",
        "                x = block(x, attention_mask)\n",
        "\n",
        "        # Final layer norm and output projection\n",
        "        x = self.ln_final(x)\n",
        "        logits = self.lm_head(x)\n",
        "\n",
        "        return logits\n",
        "\n",
        "# Create GPT-2 Small model (fits comfortably on T4)\n",
        "config_small = {\n",
        "    'vocab_size': 50257,\n",
        "    'd_model': 768,\n",
        "    'n_heads': 12,\n",
        "    'n_layers': 12,\n",
        "    'max_seq_len': 1024,\n",
        "    'dropout': 0.1\n",
        "}\n",
        "\n",
        "print(\"Creating GPT-2 Small model...\")\n",
        "model = GPT2Model(**config_small).to(device)\n",
        "\n",
        "# Model statistics\n",
        "model_stats = get_model_size(model)\n",
        "print(f\"Model created successfully!\")\n",
        "print(f\"Parameters: {model_stats['parameters']:,}\")\n",
        "print(f\"Size: {model_stats['size_mb']:.1f}MB ({model_stats['size_gb']:.2f}GB)\")\n",
        "\n",
        "# Test forward pass\n",
        "test_seq_len = 20\n",
        "test_input = torch.randint(0, config_small['vocab_size'], (2, test_seq_len)).to(device)\n",
        "\n",
        "with torch.no_grad():\n",
        "    logits = model(test_input)\n",
        "\n",
        "print(f\"Forward pass: {test_input.shape} -> {logits.shape}\")\n",
        "\n",
        "# Memory check after model creation\n",
        "check_gpu_memory()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "--2iV2Pmtliu",
        "outputId": "3f99ea30-7a94-4b76-c99c-a1516e6bab44"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating GPT-2 Small model...\n",
            "Model created successfully!\n",
            "Parameters: 124,402,944\n",
            "Size: 497.6MB (0.50GB)\n",
            "Forward pass: torch.Size([2, 20]) -> torch.Size([2, 20, 50257])\n",
            "GPU Memory - Allocated: 0.7GB, Cached: 1.3GB, Total: 15.8GB\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.733075968, 1.319108608, 15.828320256)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Text Generation\n",
        "\n",
        "Implement various sampling strategies for text generation!\n",
        "\n",
        "### Sampling Methods:\n",
        "1. **Greedy**: Always pick highest probability token\n",
        "2. **Temperature**: Control randomness (0.0 = deterministic, 1.0+ = creative)  \n",
        "3. **Top-k**: Sample from k most likely tokens\n",
        "4. **Top-p (Nucleus)**: Sample from tokens making up p% of probability mass\n",
        "\n",
        "### T4 Optimization:\n",
        "- Batch generation for efficiency\n",
        "- KV-caching could be added for longer sequences"
      ],
      "metadata": {
        "id": "aFSYaHS3t3ye"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad()\n",
        "def generate_text(model, input_ids, max_new_tokens=50, temperature=1.0,\n",
        "                  top_k=50, top_p=0.9, pad_token_id=0):\n",
        "    \"\"\"\n",
        "    Generate text using various sampling strategies.\n",
        "    Optimized for T4 GPU performance.\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    batch_size = input_ids.shape[0]\n",
        "\n",
        "    # Pre-allocate tensor for efficiency\n",
        "    max_seq_len = input_ids.shape[1] + max_new_tokens\n",
        "    if max_seq_len > model.max_seq_len:\n",
        "        max_seq_len = model.max_seq_len\n",
        "        max_new_tokens = max_seq_len - input_ids.shape[1]\n",
        "\n",
        "    generated = input_ids.clone()\n",
        "\n",
        "    for _ in range(max_new_tokens):\n",
        "        # Get current sequence length\n",
        "        curr_seq_len = generated.shape[1]\n",
        "        if curr_seq_len >= model.max_seq_len:\n",
        "            break\n",
        "\n",
        "        # Forward pass (only compute what we need)\n",
        "        logits = model(generated)\n",
        "        next_token_logits = logits[:, -1, :] / temperature\n",
        "\n",
        "        # Apply top-k filtering\n",
        "        if top_k > 0:\n",
        "            top_k_vals, top_k_indices = torch.topk(next_token_logits, min(top_k, logits.size(-1)))\n",
        "            next_token_logits[next_token_logits < top_k_vals[:, [-1]]] = -float('inf')\n",
        "\n",
        "        # Apply nucleus (top-p) filtering\n",
        "        if top_p < 1.0:\n",
        "            sorted_logits, sorted_indices = torch.sort(next_token_logits, descending=True)\n",
        "            cumulative_probs = torch.cumsum(F.softmax(sorted_logits, dim=-1), dim=-1)\n",
        "\n",
        "            # Remove tokens with cumulative probability above threshold\n",
        "            sorted_indices_to_remove = cumulative_probs > top_p\n",
        "            sorted_indices_to_remove[..., 1:] = sorted_indices_to_remove[..., :-1].clone()\n",
        "            sorted_indices_to_remove[..., 0] = False\n",
        "\n",
        "            # Scatter back to original indexing\n",
        "            indices_to_remove = sorted_indices_to_remove.scatter(1, sorted_indices, sorted_indices_to_remove)\n",
        "            next_token_logits[indices_to_remove] = -float('inf')\n",
        "\n",
        "        # Sample next token\n",
        "        probs = F.softmax(next_token_logits, dim=-1)\n",
        "        next_token = torch.multinomial(probs, num_samples=1)\n",
        "\n",
        "        # Append to sequence\n",
        "        generated = torch.cat([generated, next_token], dim=1)\n",
        "\n",
        "    return generated\n",
        "\n",
        "# Dummy tokenizer for demonstration\n",
        "class SimpleTokenizer:\n",
        "    def __init__(self, vocab_size):\n",
        "        self.vocab_size = vocab_size\n",
        "\n",
        "    def encode(self, text):\n",
        "        # Dummy encoding - in practice use real tokenizer like tiktoken\n",
        "        return torch.randint(1, self.vocab_size-100, (1, len(text.split()) + 1))\n",
        "\n",
        "    def decode(self, tokens):\n",
        "        # Dummy decoding\n",
        "        return \" \".join([f\"tok_{t.item()}\" for t in tokens.squeeze() if t != 0])\n",
        "\n",
        "# Test text generation\n",
        "tokenizer = SimpleTokenizer(config_small['vocab_size'])\n",
        "\n",
        "print(\"Testing Text Generation:\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# Test different sampling strategies\n",
        "test_prompts = [\n",
        "    \"The future of artificial intelligence\",\n",
        "    \"In a world where robots\",\n",
        "]\n",
        "\n",
        "for i, prompt in enumerate(test_prompts):\n",
        "    print(f\"\\Prompt {i+1}: '{prompt}'\")\n",
        "    input_ids = tokenizer.encode(prompt).to(device)\n",
        "\n",
        "    # Different sampling strategies\n",
        "    strategies = [\n",
        "        (\"Greedy\", {\"temperature\": 0.1, \"top_k\": 1}),\n",
        "        (\"Creative\", {\"temperature\": 1.2, \"top_k\": 50, \"top_p\": 0.9}),\n",
        "        (\"Balanced\", {\"temperature\": 0.8, \"top_k\": 40, \"top_p\": 0.95}),\n",
        "    ]\n",
        "\n",
        "    for name, params in strategies:\n",
        "        generated = generate_text(model, input_ids, max_new_tokens=20, **params)\n",
        "        decoded = tokenizer.decode(generated)\n",
        "        print(f\"   {name:>10}: {decoded[:100]}...\")\n",
        "\n",
        "print(\"\\Text generation working!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IdIvLueItxWP",
        "outputId": "52d868d5-c8b1-4a20-926e-4ef336419b65"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<>:83: SyntaxWarning: invalid escape sequence '\\P'\n",
            "<>:98: SyntaxWarning: invalid escape sequence '\\T'\n",
            "<>:83: SyntaxWarning: invalid escape sequence '\\P'\n",
            "<>:98: SyntaxWarning: invalid escape sequence '\\T'\n",
            "/tmp/ipython-input-2322836697.py:83: SyntaxWarning: invalid escape sequence '\\P'\n",
            "  print(f\"\\Prompt {i+1}: '{prompt}'\")\n",
            "/tmp/ipython-input-2322836697.py:98: SyntaxWarning: invalid escape sequence '\\T'\n",
            "  print(\"\\Text generation working!\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing Text Generation:\n",
            "==================================================\n",
            "\\Prompt 1: 'The future of artificial intelligence'\n",
            "       Greedy: tok_3663 tok_19038 tok_39148 tok_41784 tok_42058 tok_48586 tok_48586 tok_48586 tok_48586 tok_48586 t...\n",
            "     Creative: tok_3663 tok_19038 tok_39148 tok_41784 tok_42058 tok_48586 tok_48586 tok_48586 tok_40491 tok_3749 to...\n",
            "     Balanced: tok_3663 tok_19038 tok_39148 tok_41784 tok_42058 tok_48586 tok_48586 tok_48586 tok_48586 tok_48586 t...\n",
            "\\Prompt 2: 'In a world where robots'\n",
            "       Greedy: tok_715 tok_32213 tok_19790 tok_17124 tok_35049 tok_29625 tok_29625 tok_29625 tok_29625 tok_29625 to...\n",
            "     Creative: tok_715 tok_32213 tok_19790 tok_17124 tok_35049 tok_29625 tok_6403 tok_6403 tok_6403 tok_6403 tok_29...\n",
            "     Balanced: tok_715 tok_32213 tok_19790 tok_17124 tok_35049 tok_29625 tok_29625 tok_29625 tok_29625 tok_29625 to...\n",
            "\\Text generation working!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training Demo\n",
        "\n",
        "Let's implement a basic training loop to show how the model learns!\n",
        "\n",
        "### T4-Friendly Training:\n",
        "- **Small batch size**: To fit in 15GB VRAM\n",
        "- **Gradient accumulation**: Simulate larger batches\n",
        "- **Mixed precision**: Faster training with AMP\n",
        "- **Gradient clipping**: Prevent exploding gradients\n",
        "\n",
        "### Note:\n",
        "This is a demo with random data. Real training needs:\n",
        "- Proper tokenized text dataset\n",
        "- Learning rate scheduling  \n",
        "- Validation monitoring\n",
        "- Much longer training time"
      ],
      "metadata": {
        "id": "uCsFzBpOuKyZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training utilities\n",
        "from torch.cuda.amp import autocast, GradScaler\n",
        "\n",
        "def create_dummy_dataset(vocab_size, seq_len, num_samples=1000):\n",
        "    \"\"\"Create dummy training data for demonstration.\"\"\"\n",
        "    # In real training, use proper tokenized text\n",
        "    data = torch.randint(1, vocab_size-1, (num_samples, seq_len))\n",
        "    return TensorDataset(data)\n",
        "\n",
        "def train_step(model, batch, optimizer, scaler, criterion, device):\n",
        "    \"\"\"Single training step with mixed precision.\"\"\"\n",
        "    input_ids = batch[0].to(device)\n",
        "\n",
        "    # Prepare inputs and targets for causal LM\n",
        "    inputs = input_ids[:, :-1]\n",
        "    targets = input_ids[:, 1:]\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # Mixed precision forward pass\n",
        "    with autocast():\n",
        "        logits = model(inputs)\n",
        "        # Use reshape instead of view to handle non-contiguous tensors\n",
        "        loss = criterion(logits.reshape(-1, logits.size(-1)), targets.reshape(-1))\n",
        "\n",
        "    # Backward pass with gradient scaling\n",
        "    scaler.scale(loss).backward()\n",
        "    scaler.unscale_(optimizer)\n",
        "\n",
        "    # Gradient clipping\n",
        "    torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "\n",
        "    # Optimizer step\n",
        "    scaler.step(optimizer)\n",
        "    scaler.update()\n",
        "\n",
        "    return loss.item()\n",
        "\n",
        "# Training demo\n",
        "print(\"Training Demo (with dummy data)\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# Create a tiny model for training demo\n",
        "tiny_config = {\n",
        "    'vocab_size': 1000,  # Smaller vocab for demo\n",
        "    'd_model': 256,\n",
        "    'n_heads': 8,\n",
        "    'n_layers': 4,\n",
        "    'max_seq_len': 128,\n",
        "    'dropout': 0.1\n",
        "}\n",
        "\n",
        "print(\"Creating tiny model for training demo...\")\n",
        "tiny_model = GPT2Model(**tiny_config).to(device)\n",
        "tiny_stats = get_model_size(tiny_model)\n",
        "print(f\"Parameters: {tiny_stats['parameters']:,}\")\n",
        "print(f\"Size: {tiny_stats['size_mb']:.1f}MB\")\n",
        "\n",
        "# Training setup\n",
        "seq_len = 64\n",
        "batch_size = 8  # Small batch for T4\n",
        "learning_rate = 3e-4\n",
        "\n",
        "# Create dummy dataset\n",
        "dataset = create_dummy_dataset(tiny_config['vocab_size'], seq_len, num_samples=100)\n",
        "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# Training components\n",
        "optimizer = torch.optim.AdamW(tiny_model.parameters(), lr=learning_rate, betas=(0.9, 0.95))\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "scaler = GradScaler()  # For mixed precision\n",
        "\n",
        "# Training loop (just a few steps for demo)\n",
        "tiny_model.train()\n",
        "num_steps = 10\n",
        "losses = []\n",
        "\n",
        "print(f\"\\nTraining for {num_steps} steps...\")\n",
        "start_time = time.time()\n",
        "\n",
        "for step, batch in enumerate(dataloader):\n",
        "    if step >= num_steps:\n",
        "        break\n",
        "\n",
        "    loss = train_step(tiny_model, batch, optimizer, scaler, criterion, device)\n",
        "    losses.append(loss)\n",
        "\n",
        "    if step % 2 == 0:\n",
        "        print(f\"   Step {step:2d}: Loss = {loss:.4f}\")\n",
        "\n",
        "end_time = time.time()\n",
        "print(f\"\\nTraining completed in {end_time - start_time:.2f} seconds\")\n",
        "print(f\"Final loss: {losses[-1]:.4f}\")\n",
        "print(f\"Loss reduction: {losses[0] - losses[-1]:.4f}\")\n",
        "\n",
        "# Plot training loss\n",
        "plt.figure(figsize=(8, 4))\n",
        "plt.plot(losses, 'b-', linewidth=2)\n",
        "plt.title('Training Loss (Demo)')\n",
        "plt.xlabel('Step')\n",
        "plt.ylabel('Loss')\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.show()\n",
        "\n",
        "# Memory check after training\n",
        "check_gpu_memory()\n",
        "\n",
        "# Test generation after training\n",
        "print(\"\\nTesting generation after training:\")\n",
        "test_input = torch.randint(1, tiny_config['vocab_size']-1, (1, 5)).to(device)\n",
        "with torch.no_grad():\n",
        "    generated = generate_text(tiny_model, test_input, max_new_tokens=10, temperature=0.8)\n",
        "print(f\"Generated sequence: {generated.squeeze().tolist()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 859
        },
        "id": "Bo5SA5ubt-1I",
        "outputId": "3c9115ca-6689-48db-cc16-72ae1379e092"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Demo (with dummy data)\n",
            "==================================================\n",
            "Creating tiny model for training demo...\n",
            "Parameters: 3,444,224\n",
            "Size: 13.8MB\n",
            "\n",
            "Training for 10 steps...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-427750032.py:71: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()  # For mixed precision\n",
            "/tmp/ipython-input-427750032.py:21: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Step  0: Loss = 7.0356\n",
            "   Step  2: Loss = 7.0129\n",
            "   Step  4: Loss = 6.9992\n",
            "   Step  6: Loss = 6.9792\n",
            "   Step  8: Loss = 6.9963\n",
            "\n",
            "Training completed in 0.38 seconds\n",
            "Final loss: 7.0082\n",
            "Loss reduction: 0.0273\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x400 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU Memory - Allocated: 0.8GB, Cached: 1.4GB, Total: 15.8GB\n",
            "\n",
            "Testing generation after training:\n",
            "Generated sequence: [466, 130, 710, 104, 864, 864, 864, 592, 592, 108, 711, 711, 82, 373, 463]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Performance Testing & Benchmarks\n",
        "\n",
        "Let's benchmark our model on T4 to understand its performance characteristics.\n",
        "\n",
        "### What We'll Test:\n",
        "- **Forward pass speed** for different sequence lengths\n",
        "- **Memory usage** scaling\n",
        "- **Generation speed** with different batch sizes\n",
        "- **Training throughput** (tokens per second)\n",
        "\n",
        "### T4 Baseline Performance:\n",
        "- Forward pass: ~100-500 tokens/sec (depends on model size)\n",
        "- Training: ~50-200 tokens/sec with mixed precision\n",
        "- Memory efficiency: Can handle GPT-2 Small/Medium"
      ],
      "metadata": {
        "id": "uv9kf0-fuxue"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def benchmark_model(model, batch_sizes=[1, 2, 4], seq_lens=[64, 128, 256, 512]):\n",
        "    \"\"\"Comprehensive model benchmarking.\"\"\"\n",
        "    model.eval()\n",
        "    results = {'forward_pass': [], 'memory_usage': []}\n",
        "\n",
        "    print(\"Performance Benchmarking\")\n",
        "    print(\"=\" * 60)\n",
        "    print(f\"{'Batch Size':>10} {'Seq Len':>10} {'Time (ms)':>12} {'Tokens/sec':>12} {'Memory (MB)':>12}\")\n",
        "    print(\"-\" * 60)\n",
        "\n",
        "    for batch_size in batch_sizes:\n",
        "        for seq_len in seq_lens:\n",
        "            if seq_len > model.max_seq_len:\n",
        "                continue\n",
        "\n",
        "            # Clear GPU cache\n",
        "            torch.cuda.empty_cache()\n",
        "\n",
        "            # Create test input\n",
        "            test_input = torch.randint(0, 50000, (batch_size, seq_len)).to(device)\n",
        "\n",
        "            # Warmup runs\n",
        "            with torch.no_grad():\n",
        "                for _ in range(3):\n",
        "                    _ = model(test_input)\n",
        "\n",
        "            torch.cuda.synchronize()\n",
        "\n",
        "            # Benchmark runs\n",
        "            times = []\n",
        "            with torch.no_grad():\n",
        "                for _ in range(10):\n",
        "                    start = time.time()\n",
        "                    logits = model(test_input)\n",
        "                    torch.cuda.synchronize()\n",
        "                    times.append(time.time() - start)\n",
        "\n",
        "            avg_time = np.mean(times) * 1000  # Convert to ms\n",
        "            total_tokens = batch_size * seq_len\n",
        "            tokens_per_sec = total_tokens / (avg_time / 1000)\n",
        "\n",
        "            # Memory usage\n",
        "            memory_mb = torch.cuda.memory_allocated() / 1e6\n",
        "\n",
        "            results['forward_pass'].append({\n",
        "                'batch_size': batch_size,\n",
        "                'seq_len': seq_len,\n",
        "                'time_ms': avg_time,\n",
        "                'tokens_per_sec': tokens_per_sec,\n",
        "                'memory_mb': memory_mb\n",
        "            })\n",
        "\n",
        "            print(f\"{batch_size:>10} {seq_len:>10} {avg_time:>12.2f} {tokens_per_sec:>12.0f} {memory_mb:>12.1f}\")\n",
        "\n",
        "    return results\n",
        "\n",
        "# Benchmark the full GPT-2 model\n",
        "print(\"Benchmarking GPT-2 Small on T4...\")\n",
        "benchmark_results = benchmark_model(model, batch_sizes=[1, 2], seq_lens=[64, 128, 256])\n",
        "\n",
        "# Generation speed benchmark\n",
        "def benchmark_generation(model, seq_lens=[10, 20, 50], num_generations=5):\n",
        "    \"\"\"Benchmark text generation speed.\"\"\"\n",
        "    model.eval()\n",
        "    print(f\"\\nGeneration Speed Benchmark\")\n",
        "    print(\"=\" * 50)\n",
        "    print(f\"{'Seq Len':>10} {'Avg Time (s)':>15} {'Tokens/sec':>12}\")\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "    for seq_len in seq_lens:\n",
        "        times = []\n",
        "\n",
        "        for _ in range(num_generations):\n",
        "            # Random starting sequence\n",
        "            start_ids = torch.randint(1, 1000, (1, 5)).to(device)\n",
        "\n",
        "            torch.cuda.synchronize()\n",
        "            start_time = time.time()\n",
        "\n",
        "            with torch.no_grad():\n",
        "                generated = generate_text(\n",
        "                    model, start_ids,\n",
        "                    max_new_tokens=seq_len,\n",
        "                    temperature=0.8\n",
        "                )\n",
        "\n",
        "            torch.cuda.synchronize()\n",
        "            times.append(time.time() - start_time)\n",
        "\n",
        "        avg_time = np.mean(times)\n",
        "        tokens_per_sec = seq_len / avg_time\n",
        "\n",
        "        print(f\"{seq_len:>10} {avg_time:>15.3f} {tokens_per_sec:>12.1f}\")\n",
        "\n",
        "benchmark_generation(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e9FT_zW0uj43",
        "outputId": "c5a43928-826f-4bd6-bb71-06ed111cd04c"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Benchmarking GPT-2 Small on T4...\n",
            "Performance Benchmarking\n",
            "============================================================\n",
            "Batch Size    Seq Len    Time (ms)   Tokens/sec  Memory (MB)\n",
            "------------------------------------------------------------\n",
            "         1         64        10.51         6091        852.8\n",
            "         1        128        11.14        11487        865.7\n",
            "         1        256        20.52        12475        892.4\n",
            "         2         64        10.73        11930        865.7\n",
            "         2        128        20.55        12455        892.4\n",
            "         2        256        39.34        13013        942.9\n",
            "\n",
            "Generation Speed Benchmark\n",
            "==================================================\n",
            "   Seq Len    Avg Time (s)   Tokens/sec\n",
            "--------------------------------------------------\n",
            "        10           0.067        150.1\n",
            "        20           0.134        149.0\n",
            "        50           0.356        140.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Configurations for T4\n",
        "\n",
        "Here are the GPT-2 configurations that work well on T4 GPU:\n",
        "\n",
        "### Memory Guidelines:\n",
        "- **T4 VRAM**: ~15GB available\n",
        "- **GPT-2 Small**: ~0.5GB (Great for training)\n",
        "- **GPT-2 Medium**: ~1.3GB (Good for training)  \n",
        "- **GPT-2 Large**: ~3.0GB (Inference only)\n",
        "- **GPT-2 XL**: ~6.0GB (Inference only, short sequences)\n",
        "\n",
        "### Recommendations:\n",
        "- **Learning**: Use GPT-2 Small\n",
        "- **Experimentation**: GPT-2 Medium with gradient checkpointing\n",
        "- **Production inference**: GPT-2 Large with optimizations"
      ],
      "metadata": {
        "id": "8KO7djaAvAl8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Complete model configurations optimized for T4\n",
        "t4_configs = {\n",
        "    'gpt2-nano': {  # Perfect for learning/testing\n",
        "        'vocab_size': 50257,\n",
        "        'd_model': 512,\n",
        "        'n_heads': 8,\n",
        "        'n_layers': 8,\n",
        "        'max_seq_len': 1024,\n",
        "        'memory_gb': 0.2,\n",
        "        'training': 'Excellent',\n",
        "        'batch_size': 16\n",
        "    },\n",
        "\n",
        "    'gpt2-small': {  # Standard GPT-2 Small\n",
        "        'vocab_size': 50257,\n",
        "        'd_model': 768,\n",
        "        'n_heads': 12,\n",
        "        'n_layers': 12,\n",
        "        'max_seq_len': 1024,\n",
        "        'memory_gb': 0.5,\n",
        "        'training': 'Great',\n",
        "        'batch_size': 8\n",
        "    },\n",
        "\n",
        "    'gpt2-medium': {  # GPT-2 Medium with optimizations\n",
        "        'vocab_size': 50257,\n",
        "        'd_model': 1024,\n",
        "        'n_heads': 16,\n",
        "        'n_layers': 24,\n",
        "        'max_seq_len': 1024,\n",
        "        'memory_gb': 1.3,\n",
        "        'training': 'Good (use checkpointing)',\n",
        "        'batch_size': 4\n",
        "    },\n",
        "\n",
        "    'gpt2-large': {  # Inference only\n",
        "        'vocab_size': 50257,\n",
        "        'd_model': 1280,\n",
        "        'n_heads': 20,\n",
        "        'n_layers': 36,\n",
        "        'max_seq_len': 1024,\n",
        "        'memory_gb': 3.0,\n",
        "        'training': 'Inference only',\n",
        "        'batch_size': 1\n",
        "    }\n",
        "}\n",
        "\n",
        "def create_optimized_model(config_name, use_checkpointing=False):\n",
        "    \"\"\"Create model optimized for T4.\"\"\"\n",
        "    if config_name not in t4_configs:\n",
        "        raise ValueError(f\"Config {config_name} not found!\")\n",
        "\n",
        "    config = t4_configs[config_name].copy()\n",
        "\n",
        "    # Remove non-model parameters\n",
        "    model_params = {k: v for k, v in config.items()\n",
        "                   if k in ['vocab_size', 'd_model', 'n_heads', 'n_layers', 'max_seq_len']}\n",
        "\n",
        "    model = GPT2Model(**model_params, use_checkpointing=use_checkpointing)\n",
        "    return model.to(device)\n",
        "\n",
        "# Display available configurations\n",
        "import pandas as pd\n",
        "df_configs = pd.DataFrame(t4_configs).T\n",
        "print(\"T4-Optimized Model Configurations:\")\n",
        "print(\"=\" * 60)\n",
        "display_cols = ['memory_gb', 'training', 'batch_size']\n",
        "for col in display_cols:\n",
        "    if col in df_configs.columns:\n",
        "        print(f\"\\n{col.upper()}:\")\n",
        "        for idx, val in df_configs[col].items():\n",
        "            print(f\"  {idx:>15}: {val}\")\n",
        "\n",
        "# Create and test different model sizes\n",
        "print(f\"\\nTesting different model sizes:\")\n",
        "for config_name in ['gpt2-nano', 'gpt2-small']:\n",
        "    print(f\"\\n   {config_name}:\")\n",
        "    test_model = create_optimized_model(config_name)\n",
        "    stats = get_model_size(test_model)\n",
        "    print(f\"Parameters: {stats['parameters']:,}\")\n",
        "    print(f\"Memory: {stats['size_mb']:.1f}MB\")\n",
        "\n",
        "    # Quick forward pass test\n",
        "    test_input = torch.randint(0, 50257, (1, 10)).to(device)\n",
        "    with torch.no_grad():\n",
        "        output = test_model(test_input)\n",
        "    print(f\"Forward pass: {test_input.shape} -> {output.shape}\")\n",
        "\n",
        "    # Clean up\n",
        "    del test_model\n",
        "    torch.cuda.empty_cache()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v8hrCClRu2S-",
        "outputId": "a930fbad-e643-461f-c111-c97f82a5d514"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "T4-Optimized Model Configurations:\n",
            "============================================================\n",
            "\n",
            "MEMORY_GB:\n",
            "        gpt2-nano: 0.2\n",
            "       gpt2-small: 0.5\n",
            "      gpt2-medium: 1.3\n",
            "       gpt2-large: 3.0\n",
            "\n",
            "TRAINING:\n",
            "        gpt2-nano: Excellent\n",
            "       gpt2-small: Great\n",
            "      gpt2-medium: Good (use checkpointing)\n",
            "       gpt2-large: Inference only\n",
            "\n",
            "BATCH_SIZE:\n",
            "        gpt2-nano: 16\n",
            "       gpt2-small: 8\n",
            "      gpt2-medium: 4\n",
            "       gpt2-large: 1\n",
            "\n",
            "Testing different model sizes:\n",
            "\n",
            "   gpt2-nano:\n",
            "Parameters: 51,459,584\n",
            "Memory: 205.8MB\n",
            "Forward pass: torch.Size([1, 10]) -> torch.Size([1, 10, 50257])\n",
            "\n",
            "   gpt2-small:\n",
            "Parameters: 124,402,944\n",
            "Memory: 497.6MB\n",
            "Forward pass: torch.Size([1, 10]) -> torch.Size([1, 10, 50257])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wfKezGcYvK0K"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}