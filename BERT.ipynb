{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7cdf0ea3",
   "metadata": {},
   "source": [
    "# BERT from Scratch: Complete Tutorial for Google Colab\n",
    "\n",
    "Welcome to this comprehensive tutorial on building BERT (Bidirectional Encoder Representations from Transformers) from scratch! This notebook is optimized for **Google Colab with T4 GPU**.\n",
    "\n",
    "## üöÄ Quick Setup for Colab\n",
    "1. Go to **Runtime ‚Üí Change runtime type**\n",
    "2. Set **Hardware accelerator** to **GPU** (T4)\n",
    "3. Click **Save**\n",
    "4. Run all cells sequentially!\n",
    "\n",
    "## What You'll Build:\n",
    "- Complete BERT architecture from scratch\n",
    "- Masked Language Modeling (MLM) and Next Sentence Prediction (NSP)\n",
    "- Bidirectional attention mechanism\n",
    "- Pre-training and fine-tuning strategies\n",
    "- All components explained step-by-step\n",
    "\n",
    "## Key Differences: BERT vs GPT-2\n",
    "| Feature | BERT | GPT-2 |\n",
    "|---------|------|-------|\n",
    "| Architecture | Encoder-only | Decoder-only |\n",
    "| Attention | Bidirectional | Causal (unidirectional) |\n",
    "| Training | MLM + NSP | Next token prediction |\n",
    "| Use Case | Understanding | Generation |\n",
    "\n",
    "## Table of Contents\n",
    "- [Environment Setup](#environment-setup)\n",
    "- [Architecture Overview](#architecture-overview)\n",
    "- [Token & Position Embeddings](#embeddings)\n",
    "- [Bidirectional Attention](#attention)\n",
    "- [Feed-Forward Networks](#ffn)\n",
    "- [Transformer Encoder](#encoder)\n",
    "- [Complete BERT Model](#complete-model)\n",
    "- [Pre-training Tasks](#pretraining)\n",
    "- [Fine-tuning](#finetuning)\n",
    "- [Performance Testing](#performance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "15f9f349",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "GPU: NVIDIA GeForce GTX 1050 Ti\n",
      "GPU Memory: 4.2 GB\n",
      "Environment setup complete!\n"
     ]
    }
   ],
   "source": [
    "# Environment Setup for Google Colab\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import random\n",
    "\n",
    "# Check GPU availability\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    gpu_name = torch.cuda.get_device_name(0)\n",
    "    gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1e9\n",
    "    print(f\"GPU: {gpu_name}\")\n",
    "    print(f\"GPU Memory: {gpu_memory:.1f} GB\")\n",
    "    \n",
    "    # Enable optimizations for T4\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    torch.cuda.empty_cache()\n",
    "else:\n",
    "    print(\"GPU not available. Switch to GPU runtime!\")\n",
    "\n",
    "# Set seeds for reproducibility\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "set_seed(42)\n",
    "print(\"Environment setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ead7b1",
   "metadata": {},
   "source": [
    "## üß† BERT Architecture Overview\n",
    "\n",
    "**BERT (Bidirectional Encoder Representations from Transformers)** is an **encoder-only Transformer** architecture designed for **natural language understanding (NLU)** tasks.  \n",
    "It achieves state-of-the-art performance across multiple benchmarks by leveraging deep bidirectional attention and large-scale unsupervised pre-training.\n",
    "\n",
    "---\n",
    "\n",
    "### üîç Key Innovations\n",
    "\n",
    "1. **Bidirectional Self-Attention**  \n",
    "   Unlike left-to-right models (e.g., GPT), BERT jointly attends to **both left and right context** in all layers, allowing richer contextual understanding.\n",
    "\n",
    "2. **Masked Language Modeling (MLM)**  \n",
    "   Randomly masks a subset of input tokens and trains the model to **predict the original tokens** based on surrounding context.\n",
    "\n",
    "3. **Next Sentence Prediction (NSP)**  \n",
    "   A binary classification task that helps BERT learn **inter-sentence relationships**, improving performance on QA and entailment tasks.\n",
    "\n",
    "4. **Pre-train ‚Üí Fine-tune Paradigm**  \n",
    "   BERT is **pre-trained** on massive unlabeled corpora (BooksCorpus + Wikipedia) and later **fine-tuned** on specific downstream tasks with minimal task-specific architecture changes.\n",
    "\n",
    "---\n",
    "\n",
    "### üèóÔ∏è Architectural Components\n",
    "\n",
    "**Input Pipeline:**\n",
    "$ Input Text ‚Üí Tokenization ‚Üí Embeddings (Token + Segment + Position) $\n",
    "\n",
    "**Model Stack:**\n",
    "$ Embeddings ‚Üí Transformer Encoder Blocks (√ó12 for BERT-Base) $\n",
    "\n",
    "\n",
    "**Output Heads:**\n",
    "- **[CLS] token** ‚Üí Sentence-level tasks (e.g., classification, entailment)  \n",
    "- **All token embeddings** ‚Üí Token-level tasks (e.g., NER, QA)\n",
    "\n",
    "---\n",
    "\n",
    "<div align=\"center\">\n",
    "  <img src=\"https://en.wikipedia.org/wiki/BERT_(language_model)#/media/File:BERT_embeddings_01.png\" \n",
    "       alt=\"BERT model architecture diagram\" width=\"600\"/>\n",
    "\n",
    "  <p><em>Figure: Simplified BERT architecture overview (Source: Wikimedia, CC BY-SA 4.0)</em></p>\n",
    "</div>\n",
    "\n",
    "---\n",
    "\n",
    "### ‚öôÔ∏è Model Configurations\n",
    "\n",
    "| Model Variant | Layers | Hidden Size | Attention Heads | Parameters |\n",
    "|----------------|---------|--------------|------------------|-------------|\n",
    "| **BERT-Base**  | 12      | 768          | 12               | ~110M       |\n",
    "| **BERT-Large** | 24      | 1024         | 16               | ~340M       |\n",
    "\n",
    "---\n",
    "\n",
    "### üßÆ Mathematical Intuition\n",
    "\n",
    "#### Masked Language Modeling (MLM)\n",
    "\n",
    "<div align=\"center\">\n",
    "  <img src=\"https://en.wikipedia.org/wiki/BERT_(language_model)#/media/File:BERT_masked_language_modelling_task.png\" \n",
    "       alt=\"Masked Language Modeling\" width=\"600\"/>\n",
    "\n",
    "  <p><em>Figure: Masked Language Modeling Task (Source: Wikimedia, CC BY-SA 4.0)</em></p>\n",
    "</div>\n",
    "\n",
    "Given an input token sequence $ x = (x_1, x_2, ‚Ä¶, x_N) $, we mask a subset of positions $ M \\subset \\{1,‚Ä¶,N\\} $ and replace those tokens with a special $[MASK]$ token (or sometimes a random token or remain unchanged) during pre-training. The model outputs contextualized representations and then computes a softmax over the vocabulary for each masked position $ i \\in M $. The loss is:\n",
    "\n",
    "$$\n",
    "\\mathcal{L}_{\\text{MLM}} = - \\frac{1}{|M|} \\sum_{i \\in M} \\log \\; P( x_i \\mid x_{\\setminus M} )\n",
    "$$\n",
    "\n",
    "where $ x_{\\setminus M} $ denotes the input sequence with masked positions.  \n",
    "The training objective is to maximise the probability of the true token at each masked position.\n",
    "\n",
    "#### Next Sentence Prediction (NSP) \n",
    "\n",
    "<div align=\"center\">\n",
    "  <img src=\"https://en.wikipedia.org/wiki/BERT_(language_model)#/media/File:BERT_next_sequence_prediction_task.png\" \n",
    "       alt=\"Next Sentence Prediction\" width=\"600\"/>\n",
    "\n",
    "  <p><em>Figure: Next Sentence Prediction (Source: Wikimedia, CC BY-SA 4.0)</em></p>\n",
    "</div>\n",
    "\n",
    "Given a pair of sentences $ (A, B) $, the model receives the tokenized input:\n",
    "$ [CLS] ‚Ä¶ tokens of A ‚Ä¶ [SEP] ‚Ä¶ tokens of B ‚Ä¶ [SEP] $\n",
    "\n",
    "and produces an embedding for the $ [CLS] $ token, say $ h_{\\text{CLS}} $. A binary classifier atop $ h_{\\text{CLS}} $ predicts whether B follows A (label = 1) or not (label = 0). The loss is:\n",
    "\n",
    "$$\n",
    "\\mathcal{L}_{\\text{NSP}} = - \\frac{1}{2} \\Big( \\log P(\\text{IsNext} \\mid h_{\\text{CLS}}) + \\log P(\\text{NotNext} \\mid h_{\\text{CLS}}) \\Big)\n",
    "$$\n",
    "\n",
    "In practice with a mini-batch this becomes the average negative log-likelihood over the sentence pair labels.\n",
    "\n",
    "#### Combined Pre-training Loss\n",
    "\n",
    "The total pre-training loss is a sum of the two objectives (ignoring other minor regularisation terms):\n",
    "\n",
    "$$\n",
    "\\mathcal{L} = \\mathcal{L}_{\\text{MLM}} + \\mathcal{L}_{\\text{NSP}}\n",
    "$$\n",
    "\n",
    "By minimising $ \\mathcal{L} $, the model simultaneously learns token-level bidirectional context (via MLM) and inter-sentence relationships (via NSP).\n",
    "\n",
    "---\n",
    "\n",
    "### üí° Hardware Considerations (NVIDIA T4)\n",
    "\n",
    "- **BERT-Base** can be trained comfortably on a single NVIDIA T4 GPU.  \n",
    "- **BERT-Large** typically requires **gradient checkpointing** or **mixed-precision training** to fit GPU memory.  \n",
    "- Despite bidirectional attention, BERT tends to be **more memory-efficient** than autoregressive models (e.g., GPT-2) for equivalent sequence length, because of encoder-only design and no autoregressive masking.\n",
    "\n",
    "---\n",
    "\n",
    "### üìö Reference\n",
    "\n",
    "Devlin, J., Chang, M.-W., Lee, K., & Toutanova, K. (2019).  \n",
    "**BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding.**  \n",
    "*Proceedings of NAACL-HLT*, 4171‚Äì4186.  \n",
    "[https://arxiv.org/abs/1810.04805](https://arxiv.org/abs/1810.04805)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3def5990",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " GPU Memory - Allocated: 0.78GB, Cached: 0.84GB, Total: 4.2GB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.776302592, 0.843055104, 4.227465216)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Utility Functions\n",
    "def get_model_size(model):\n",
    "    \"\"\"Calculate model size in parameters and memory.\"\"\"\n",
    "    param_count = sum(p.numel() for p in model.parameters())\n",
    "    param_size = sum(p.numel() * p.element_size() for p in model.parameters())\n",
    "    buffer_size = sum(b.numel() * b.element_size() for b in model.buffers())\n",
    "    total_size = param_size + buffer_size\n",
    "    \n",
    "    return {\n",
    "        'parameters': param_count,\n",
    "        'size_mb': total_size / 1e6,\n",
    "        'size_gb': total_size / 1e9\n",
    "    }\n",
    "\n",
    "def check_gpu_memory():\n",
    "    \"\"\"Check GPU memory usage.\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        allocated = torch.cuda.memory_allocated() / 1e9\n",
    "        cached = torch.cuda.memory_reserved() / 1e9\n",
    "        total = torch.cuda.get_device_properties(0).total_memory / 1e9\n",
    "        print(f\" GPU Memory - Allocated: {allocated:.2f}GB, Cached: {cached:.2f}GB, Total: {total:.1f}GB\")\n",
    "        return allocated, cached, total\n",
    "    return 0, 0, 0\n",
    "\n",
    "# Initial memory check\n",
    "check_gpu_memory()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33787a10",
   "metadata": {},
   "source": [
    "## Token, Position & Segment Embeddings\n",
    "\n",
    "BERT uses **three types of embeddings** that are summed together:\n",
    "\n",
    "### 1. Token Embeddings\n",
    "- Convert word pieces to vectors\n",
    "- Vocabulary size: 30,522 (WordPiece tokenization)\n",
    "\n",
    "### 2. Position Embeddings\n",
    "- Learned positional encodings (not sinusoidal like original Transformer)\n",
    "- Maximum sequence length: 512 tokens\n",
    "\n",
    "### 3. Segment Embeddings\n",
    "- Distinguish between sentence A and sentence B\n",
    "- Used for tasks like NSP and QA\n",
    "- Only 2 embeddings: [0, 1]\n",
    "\n",
    "### Mathematical Formula:\n",
    "$ E_{total} = E_{token} + E_{position} + E_{segment} $\n",
    "### Special Tokens:\n",
    "- **[CLS]**: Classification token (always first)\n",
    "- **[SEP]**: Separator between sentences\n",
    "- **[MASK]**: Masked token for MLM\n",
    "- **[PAD]**: Padding token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "441e1aa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT Embedding Test:\n",
      "Input IDs: torch.Size([2, 20])\n",
      "Segment IDs: torch.Size([2, 20])\n",
      "Output embeddings: torch.Size([2, 20, 768])\n",
      "Memory: 95.3MB\n"
     ]
    }
   ],
   "source": [
    "class BERTEmbedding(nn.Module):\n",
    "    \"\"\"\n",
    "    BERT Embedding: Token + Position + Segment embeddings.\n",
    "    \n",
    "    Args:\n",
    "        vocab_size (int): Vocabulary size\n",
    "        d_model (int): Embedding dimension\n",
    "        max_seq_len (int): Maximum sequence length\n",
    "        dropout (float): Dropout probability\n",
    "    \"\"\"\n",
    "    def __init__(self, vocab_size, d_model, max_seq_len=512, dropout=0.1):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Token embeddings\n",
    "        self.token_embedding = nn.Embedding(vocab_size, d_model, padding_idx=0)\n",
    "        \n",
    "        # Position embeddings (learned, not sinusoidal)\n",
    "        self.position_embedding = nn.Embedding(max_seq_len, d_model)\n",
    "        \n",
    "        # Segment embeddings (for sentence A/B)\n",
    "        self.segment_embedding = nn.Embedding(2, d_model)\n",
    "        \n",
    "        # Layer normalization and dropout\n",
    "        self.layer_norm = nn.LayerNorm(d_model, eps=1e-12)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        # Initialize weights\n",
    "        self._init_weights()\n",
    "        \n",
    "    def _init_weights(self):\n",
    "        \"\"\"Initialize embedding weights.\"\"\"\n",
    "        nn.init.normal_(self.token_embedding.weight, mean=0, std=0.02)\n",
    "        nn.init.normal_(self.position_embedding.weight, mean=0, std=0.02)\n",
    "        nn.init.normal_(self.segment_embedding.weight, mean=0, std=0.02)\n",
    "        \n",
    "    def forward(self, input_ids, segment_ids=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            input_ids: (batch_size, seq_len)\n",
    "            segment_ids: (batch_size, seq_len) - optional, defaults to all 0s\n",
    "        \"\"\"\n",
    "        batch_size, seq_len = input_ids.size()\n",
    "        \n",
    "        # Create position IDs\n",
    "        position_ids = torch.arange(seq_len, device=input_ids.device)\n",
    "        position_ids = position_ids.unsqueeze(0).expand_as(input_ids)\n",
    "        \n",
    "        # Default segment IDs if not provided\n",
    "        if segment_ids is None:\n",
    "            segment_ids = torch.zeros_like(input_ids)\n",
    "        \n",
    "        # Get embeddings\n",
    "        token_emb = self.token_embedding(input_ids)\n",
    "        position_emb = self.position_embedding(position_ids)\n",
    "        segment_emb = self.segment_embedding(segment_ids)\n",
    "        \n",
    "        # Sum all embeddings\n",
    "        embeddings = token_emb + position_emb + segment_emb\n",
    "        \n",
    "        # Apply layer norm and dropout\n",
    "        embeddings = self.layer_norm(embeddings)\n",
    "        embeddings = self.dropout(embeddings)\n",
    "        \n",
    "        return embeddings\n",
    "\n",
    "# Test BERT embeddings\n",
    "vocab_size = 30522  # BERT vocabulary size\n",
    "d_model = 768       # BERT-Base hidden size\n",
    "max_seq_len = 512\n",
    "\n",
    "bert_embedding = BERTEmbedding(vocab_size, d_model, max_seq_len).to(device)\n",
    "\n",
    "# Test with sample input\n",
    "batch_size = 2\n",
    "seq_len = 20\n",
    "sample_input_ids = torch.randint(100, vocab_size-100, (batch_size, seq_len)).to(device)\n",
    "sample_segment_ids = torch.cat([\n",
    "    torch.zeros(batch_size, seq_len//2, dtype=torch.long),\n",
    "    torch.ones(batch_size, seq_len//2, dtype=torch.long)\n",
    "], dim=1).to(device)\n",
    "\n",
    "embeddings = bert_embedding(sample_input_ids, sample_segment_ids)\n",
    "\n",
    "print(f\"BERT Embedding Test:\")\n",
    "print(f\"Input IDs: {sample_input_ids.shape}\")\n",
    "print(f\"Segment IDs: {sample_segment_ids.shape}\")\n",
    "print(f\"Output embeddings: {embeddings.shape}\")\n",
    "print(f\"Memory: {get_model_size(bert_embedding)['size_mb']:.1f}MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fb2e738",
   "metadata": {},
   "source": [
    "## üîÅ Bidirectional Multi-Head Attention\n",
    "\n",
    "Unlike GPT-2‚Äôs **causal attention**, BERT employs **bidirectional self-attention**, meaning that **each token attends to all other tokens** in the sequence ‚Äî both to its left and right.  \n",
    "This allows BERT to build deep contextual representations ideal for **language understanding** tasks.\n",
    "\n",
    "---\n",
    "\n",
    "### ‚öñÔ∏è Key Differences from GPT-2\n",
    "\n",
    "| Feature | **BERT (Bidirectional)** | **GPT-2 (Causal)** |\n",
    "|----------|---------------------------|--------------------|\n",
    "| **Attention Mask** | No causal mask ‚Üí full visibility | Causal mask ‚Üí only left context visible |\n",
    "| **Context Access** | Sees entire sentence (past + future) | Sees only past tokens |\n",
    "| **Use Case** | Understanding / classification tasks | Text generation / prediction |\n",
    "| **Mask Type** | Padding mask only | Padding + causal mask |\n",
    "\n",
    "‚úÖ **Full-context modeling**  \n",
    "‚úÖ **Ignores padding tokens**  \n",
    "‚ùå **No autoregressive constraint**\n",
    "\n",
    "---\n",
    "\n",
    "### üéØ Attention Visualization\n",
    "\n",
    "| GPT-2 (Causal) | BERT (Bidirectional) |\n",
    "|:---------------:|:-------------------:|\n",
    "| $\\begin{bmatrix}1 & 0 & 0 & 0 \\\\ 1 & 1 & 0 & 0 \\\\ 1 & 1 & 1 & 0 \\\\ 1 & 1 & 1 & 1 \\end{bmatrix} $ | $ \\begin{bmatrix}1 & 1 & 1 & 1 \\\\ 1 & 1 & 1 & 1 \\\\ 1 & 1 & 1 & 1 \\\\ 1 & 1 & 1 & 1 \\end{bmatrix} $ |\n",
    "\n",
    "Each matrix entry $ M_{ij} $ indicates whether token $ i $ can attend to token $ j $.  \n",
    "- GPT-2 applies a **lower-triangular causal mask** ‚Üí only previous tokens visible.  \n",
    "- BERT applies a **full mask** ‚Üí every token can attend to every other token.\n",
    "\n",
    "---\n",
    "\n",
    "### üßÆ Mathematical Formulation\n",
    "\n",
    "**Scaled Dot-Product Attention:**\n",
    "$$\n",
    "\\text{Attention}(Q, K, V) = \\text{softmax}\\left(\\frac{QK^\\top}{\\sqrt{d_k}}\\right)V\n",
    "$$\n",
    "\n",
    "where  \n",
    "- $ Q, K, V $ = query, key, and value matrices derived from input embeddings,  \n",
    "- $ d_k $ = key dimensionality.\n",
    "\n",
    "**Multi-Head Attention:**\n",
    "\n",
    "$$\n",
    "\\text{MultiHead}(Q, K, V) = \\text{Concat}(\\text{head}_1, ..., \\text{head}_h) W^O\n",
    "$$\n",
    "$$\n",
    "\\text{head}_i = \\text{Attention}(QW_i^Q, KW_i^K, VW_i^V)\n",
    "$$\n",
    "\n",
    "This allows BERT to learn multiple attention ‚Äúviews‚Äù of the same input (e.g., syntactic vs. semantic).\n",
    "\n",
    "---\n",
    "\n",
    "### üß† Why Bidirectional Attention Matters\n",
    "\n",
    "- **Deep Language Understanding:** Enables simultaneous access to *past and future* context ‚Üí essential for tasks like sentence classification and natural language inference.  \n",
    "- **Masked Token Prediction (MLM):** Predicts masked tokens using *both* left and right contexts.  \n",
    "- **Sentence Relationship Tasks (NSP):** Learns inter-sentence coherence by seeing full sentence pairs.\n",
    "\n",
    "---\n",
    "\n",
    "### üìö References\n",
    "\n",
    "- Vaswani, A. et al. (2017). *Attention Is All You Need.* NeurIPS.  \n",
    "- Devlin, J., Chang, M.-W., Lee, K., & Toutanova, K. (2019). *BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding.*  \n",
    "  [https://arxiv.org/abs/1810.04805](https://arxiv.org/abs/1810.04805)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c74b28db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Multi-Head Attention Test:\n",
      "   Input: torch.Size([2, 10, 768])\n",
      "   Attention mask: torch.Size([2, 10])\n",
      "   Output: torch.Size([2, 10, 768])\n",
      "   Attention weights: torch.Size([2, 12, 10, 10])\n",
      "   Parameters: 2,362,368\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x400 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " GPU Memory - Allocated: 0.78GB, Cached: 0.94GB, Total: 4.2GB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.776632832, 0.939524096, 4.227465216)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    \"\"\"\n",
    "    Bidirectional Multi-Head Self-Attention for BERT.\n",
    "    \n",
    "    Args:\n",
    "        d_model (int): Model dimension\n",
    "        n_heads (int): Number of attention heads\n",
    "        dropout (float): Dropout probability\n",
    "    \"\"\"\n",
    "    def __init__(self, d_model, n_heads, dropout=0.1):\n",
    "        super().__init__()\n",
    "        assert d_model % n_heads == 0\n",
    "        \n",
    "        self.d_model = d_model\n",
    "        self.n_heads = n_heads\n",
    "        self.d_k = d_model // n_heads\n",
    "        \n",
    "        # Q, K, V projections\n",
    "        self.w_q = nn.Linear(d_model, d_model, bias=True)\n",
    "        self.w_k = nn.Linear(d_model, d_model, bias=True)\n",
    "        self.w_v = nn.Linear(d_model, d_model, bias=True)\n",
    "        \n",
    "        # Output projection\n",
    "        self.w_o = nn.Linear(d_model, d_model, bias=True)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        # Initialize weights\n",
    "        self._init_weights()\n",
    "        \n",
    "    def _init_weights(self):\n",
    "        \"\"\"Initialize weights following BERT paper.\"\"\"\n",
    "        for module in [self.w_q, self.w_k, self.w_v, self.w_o]:\n",
    "            nn.init.normal_(module.weight, mean=0, std=0.02)\n",
    "            if module.bias is not None:\n",
    "                nn.init.zeros_(module.bias)\n",
    "    \n",
    "    def forward(self, x, attention_mask=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: (batch_size, seq_len, d_model)\n",
    "            attention_mask: (batch_size, seq_len) - 1 for real tokens, 0 for padding\n",
    "        \"\"\"\n",
    "        batch_size, seq_len, d_model = x.shape\n",
    "        \n",
    "        # Linear projections\n",
    "        Q = self.w_q(x)  # (B, L, d_model)\n",
    "        K = self.w_k(x)\n",
    "        V = self.w_v(x)\n",
    "        \n",
    "        # Reshape for multi-head attention\n",
    "        Q = Q.view(batch_size, seq_len, self.n_heads, self.d_k).transpose(1, 2)\n",
    "        K = K.view(batch_size, seq_len, self.n_heads, self.d_k).transpose(1, 2)\n",
    "        V = V.view(batch_size, seq_len, self.n_heads, self.d_k).transpose(1, 2)\n",
    "        # Now: (B, n_heads, L, d_k)\n",
    "        \n",
    "        # Scaled dot-product attention\n",
    "        scores = torch.matmul(Q, K.transpose(-2, -1)) / math.sqrt(self.d_k)\n",
    "        # scores: (B, n_heads, L, L)\n",
    "        \n",
    "        # Apply attention mask (for padding)\n",
    "        if attention_mask is not None:\n",
    "            # Expand mask for all heads: (B, 1, 1, L)\n",
    "            attention_mask = attention_mask.unsqueeze(1).unsqueeze(2)\n",
    "            # Mask with large negative value\n",
    "            scores = scores.masked_fill(attention_mask == 0, -1e9)\n",
    "        \n",
    "        # Softmax and dropout\n",
    "        attention_weights = F.softmax(scores, dim=-1)\n",
    "        attention_weights = self.dropout(attention_weights)\n",
    "        \n",
    "        # Apply attention to values\n",
    "        context = torch.matmul(attention_weights, V)  # (B, n_heads, L, d_k)\n",
    "        \n",
    "        # Concatenate heads\n",
    "        context = context.transpose(1, 2).contiguous()\n",
    "        context = context.view(batch_size, seq_len, d_model)\n",
    "        \n",
    "        # Output projection\n",
    "        output = self.w_o(context)\n",
    "        \n",
    "        return output, attention_weights\n",
    "\n",
    "# Test bidirectional attention\n",
    "n_heads = 12  # BERT-Base uses 12 heads\n",
    "attention = MultiHeadAttention(d_model, n_heads).to(device)\n",
    "\n",
    "# Create sample input with padding\n",
    "sample_input = torch.randn(2, 10, d_model).to(device)\n",
    "# Attention mask: 1 for real tokens, 0 for padding\n",
    "attention_mask = torch.ones(2, 10).to(device)\n",
    "attention_mask[0, 7:] = 0  # Pad last 3 tokens of first sequence\n",
    "attention_mask[1, 9:] = 0  # Pad last token of second sequence\n",
    "\n",
    "attn_output, attn_weights = attention(sample_input, attention_mask)\n",
    "\n",
    "print(f\"   Multi-Head Attention Test:\")\n",
    "print(f\"   Input: {sample_input.shape}\")\n",
    "print(f\"   Attention mask: {attention_mask.shape}\")\n",
    "print(f\"   Output: {attn_output.shape}\")\n",
    "print(f\"   Attention weights: {attn_weights.shape}\")\n",
    "print(f\"   Parameters: {sum(p.numel() for p in attention.parameters()):,}\")\n",
    "\n",
    "# Visualize attention pattern\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(attn_weights[0, 0].detach().cpu(), cmap='viridis')\n",
    "plt.title('BERT: Bidirectional Attention (Head 0)')\n",
    "plt.xlabel('Key Position')\n",
    "plt.ylabel('Query Position')\n",
    "plt.colorbar()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(attention_mask[0].unsqueeze(0).repeat(10, 1).cpu(), cmap='gray')\n",
    "plt.title('Attention Mask (1=real, 0=padding)')\n",
    "plt.xlabel('Token Position')\n",
    "plt.ylabel('Token Position')\n",
    "plt.colorbar()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "check_gpu_memory()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a660f8a5",
   "metadata": {},
   "source": [
    "## ‚öôÔ∏è Feed-Forward Network (FFN)\n",
    "\n",
    "In BERT, each Transformer encoder block includes a **Position-wise Feed-Forward Network (FFN)** applied independently to each token‚Äôs hidden state.  \n",
    "It is architecturally identical to GPT-2‚Äôs FFN, except that BERT uses the **GELU activation** instead of ReLU.\n",
    "\n",
    "---\n",
    "\n",
    "### üß± Architecture\n",
    "$$\n",
    "\\begin{aligned}\n",
    "&\\text{Input } (d_{\\text{model}} = 768) \\\\\n",
    "&\\downarrow \\\\\n",
    "&\\text{Linear (expand)} \\rightarrow d_{\\text{ff}} = 4 \\times d_{\\text{model}} = 3072 \\\\\n",
    "&\\downarrow \\\\\n",
    "&\\text{GELU activation} \\\\\n",
    "&\\downarrow \\\\\n",
    "&\\text{Linear (contract)} \\rightarrow d_{\\text{model}} = 768 \\\\\n",
    "&\\downarrow \\\\\n",
    "&\\text{Output}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Formally, for hidden input $ h \\in \\mathbb{R}^{d_{\\text{model}}} $:\n",
    "\n",
    "$$\n",
    "\\text{FFN}(h) = W_2 \\cdot \\text{GELU}(W_1 h + b_1) + b_2\n",
    "$$\n",
    "\n",
    "where  \n",
    "- $ W_1 \\in \\mathbb{R}^{d_{\\text{ff}} \\times d_{\\text{model}}} $\n",
    "- $ W_2 \\in \\mathbb{R}^{d_{\\text{model}} \\times d_{\\text{ff}}} $ \n",
    "- Typically $ d_{\\text{ff}} = 4 \\times d_{\\text{model}} $\n",
    "\n",
    "---\n",
    "\n",
    "### üßÆ GELU Activation\n",
    "\n",
    "**Gaussian Error Linear Unit (GELU)** combines ideas from ReLU and dropout by weighting inputs according to their probability under a Gaussian distribution.\n",
    "\n",
    "$$\n",
    "\\text{GELU}(x) = x \\cdot \\Phi(x) = x \\cdot P(X \\le x), \\quad X \\sim \\mathcal{N}(0, 1)\n",
    "$$\n",
    "\n",
    "where $ \\Phi(x) $ is the standard normal CDF.\n",
    "\n",
    "**Approximation used in BERT (Hendrycks & Gimpel, 2016):**\n",
    "\n",
    "$$\n",
    "\\text{GELU}(x) \\approx 0.5x \\left( 1 + \\tanh\\!\\left[\\sqrt{\\frac{2}{\\pi}}(x + 0.044715x^3)\\right] \\right)\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### üí° Why BERT Uses GELU (vs. ReLU)\n",
    "\n",
    "| Property | **ReLU** | **GELU** |\n",
    "|-----------|-----------|-----------|\n",
    "| Activation shape | Hard threshold at 0 | Smooth probabilistic gating |\n",
    "| Derivative | Discontinuous at 0 | Smooth everywhere |\n",
    "| Output for small negatives | 0 | Slightly negative (non-monotonic) |\n",
    "| Effect | Sparse activations | Soft stochastic regularization |\n",
    "\n",
    "**Advantages in BERT:**\n",
    "- Provides **smoother gradient flow** during optimization  \n",
    "- Introduces subtle nonlinearity beneficial for **semantic understanding**  \n",
    "- Handles small negative activations gracefully ‚Üí more stable training  \n",
    "\n",
    "---\n",
    "\n",
    "### üìò Reference\n",
    "\n",
    "- Hendrycks, D., & Gimpel, K. (2016). *Gaussian Error Linear Units (GELUs).* arXiv:1606.08415  \n",
    "- Devlin, J., Chang, M.-W., Lee, K., & Toutanova, K. (2019). *BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding.* NAACL-HLT.  \n",
    "  [https://arxiv.org/abs/1810.04805](https://arxiv.org/abs/1810.04805)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e7e0d43c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Feed-Forward Network Test:\n",
      "   Input: torch.Size([2, 10, 768])\n",
      "   Output: torch.Size([2, 10, 768])\n",
      "   Expansion: 768 ‚Üí 3072 ‚Üí 768\n",
      "   Parameters: 4,722,432\n"
     ]
    }
   ],
   "source": [
    "class FeedForward(nn.Module):\n",
    "    \"\"\"\n",
    "    Position-wise Feed-Forward Network with GELU activation.\n",
    "    \n",
    "    Args:\n",
    "        d_model (int): Model dimension\n",
    "        d_ff (int): Feed-forward dimension (typically 4 * d_model)\n",
    "        dropout (float): Dropout probability\n",
    "    \"\"\"\n",
    "    def __init__(self, d_model, d_ff=None, dropout=0.1):\n",
    "        super().__init__()\n",
    "        if d_ff is None:\n",
    "            d_ff = 4 * d_model\n",
    "            \n",
    "        self.linear1 = nn.Linear(d_model, d_ff)\n",
    "        self.gelu = nn.GELU()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.linear2 = nn.Linear(d_ff, d_model)\n",
    "        \n",
    "        # Initialize weights\n",
    "        self._init_weights()\n",
    "        \n",
    "    def _init_weights(self):\n",
    "        \"\"\"Initialize weights following BERT paper.\"\"\"\n",
    "        nn.init.normal_(self.linear1.weight, mean=0, std=0.02)\n",
    "        nn.init.normal_(self.linear2.weight, mean=0, std=0.02)\n",
    "        nn.init.zeros_(self.linear1.bias)\n",
    "        nn.init.zeros_(self.linear2.bias)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.linear1(x)\n",
    "        x = self.gelu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.linear2(x)\n",
    "        return x\n",
    "\n",
    "# Test feed-forward network\n",
    "d_ff = 4 * d_model  # 3072 for BERT-Base\n",
    "ffn = FeedForward(d_model, d_ff).to(device)\n",
    "\n",
    "sample_input = torch.randn(2, 10, d_model).to(device)\n",
    "ffn_output = ffn(sample_input)\n",
    "\n",
    "print(f\"   Feed-Forward Network Test:\")\n",
    "print(f\"   Input: {sample_input.shape}\")\n",
    "print(f\"   Output: {ffn_output.shape}\")\n",
    "print(f\"   Expansion: {d_model} ‚Üí {d_ff} ‚Üí {d_model}\")\n",
    "print(f\"   Parameters: {sum(p.numel() for p in ffn.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc919e5",
   "metadata": {},
   "source": [
    "## Transformer Encoder Block\n",
    "\n",
    "BERT uses the **encoder** portion of the original Transformer with **post-layer normalization** (unlike GPT-2's pre-norm).\n",
    "\n",
    "### Architecture:\n",
    "\n",
    " BERT uses **post-norm**:\n",
    "\n",
    "\n",
    "### Post-Norm vs Pre-Norm:\n",
    "- **Post-norm** (BERT): Normalizes after residual addition\n",
    "- **Pre-norm** (GPT-2): Normalizes before transformation\n",
    "- Post-norm was standard in original Transformer paper\n",
    "- Pre-norm became popular later for deeper models\n",
    "\n",
    "### Mathematical Flow:\n",
    "$ h1 = LayerNorm(x + MultiHeadAttention(x)) $\n",
    "\n",
    "$ h2 = LayerNorm(h1 + FeedForward(h1)) $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b2f44574",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Transformer Encoder Block Test:\n",
      "   Input: torch.Size([2, 10, 768])\n",
      "   Output: torch.Size([2, 10, 768])\n",
      "   Parameters: 7,087,872\n",
      " GPU Memory - Allocated: 0.78GB, Cached: 0.94GB, Total: 4.2GB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.776632832, 0.939524096, 4.227465216)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class TransformerEncoderBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    Single BERT Transformer Encoder block with post-layer normalization.\n",
    "    \n",
    "    Args:\n",
    "        d_model (int): Model dimension\n",
    "        n_heads (int): Number of attention heads\n",
    "        d_ff (int): Feed-forward dimension\n",
    "        dropout (float): Dropout probability\n",
    "    \"\"\"\n",
    "    def __init__(self, d_model, n_heads, d_ff=None, dropout=0.1):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Multi-head attention\n",
    "        self.attention = MultiHeadAttention(d_model, n_heads, dropout)\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "        self.layer_norm1 = nn.LayerNorm(d_model, eps=1e-12)\n",
    "        \n",
    "        # Feed-forward network\n",
    "        self.feed_forward = FeedForward(d_model, d_ff, dropout)\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "        self.layer_norm2 = nn.LayerNorm(d_model, eps=1e-12)\n",
    "        \n",
    "    def forward(self, x, attention_mask=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: (batch_size, seq_len, d_model)\n",
    "            attention_mask: (batch_size, seq_len)\n",
    "        \"\"\"\n",
    "        # Multi-head attention with residual connection and layer norm\n",
    "        attn_output, attn_weights = self.attention(x, attention_mask)\n",
    "        attn_output = self.dropout1(attn_output)\n",
    "        x = self.layer_norm1(x + attn_output)  # Post-norm\n",
    "        \n",
    "        # Feed-forward with residual connection and layer norm\n",
    "        ff_output = self.feed_forward(x)\n",
    "        ff_output = self.dropout2(ff_output)\n",
    "        x = self.layer_norm2(x + ff_output)  # Post-norm\n",
    "        \n",
    "        return x, attn_weights\n",
    "\n",
    "# Test encoder block\n",
    "encoder_block = TransformerEncoderBlock(d_model, n_heads, d_ff).to(device)\n",
    "\n",
    "sample_input = torch.randn(2, 10, d_model).to(device)\n",
    "attention_mask = torch.ones(2, 10).to(device)\n",
    "block_output, _ = encoder_block(sample_input, attention_mask)\n",
    "\n",
    "print(f\"   Transformer Encoder Block Test:\")\n",
    "print(f\"   Input: {sample_input.shape}\")\n",
    "print(f\"   Output: {block_output.shape}\")\n",
    "print(f\"   Parameters: {sum(p.numel() for p in encoder_block.parameters()):,}\")\n",
    "\n",
    "check_gpu_memory()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c9dc3b6",
   "metadata": {},
   "source": [
    "## Complete BERT Model\n",
    "\n",
    "Now let's assemble the complete BERT model!\n",
    "\n",
    "### üß© Full Architecture\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "&\\text{Input Text} \\\\\n",
    "&\\downarrow \\\\\n",
    "&[\\text{Tokenization}] \\;\\rightarrow\\; \\text{Input IDs + Segment IDs} \\\\\n",
    "&\\downarrow \\\\\n",
    "&\\text{Embeddings (Token + Position + Segment)} \\\\\n",
    "&\\downarrow \\\\\n",
    "&\\text{Transformer Encoder} \\times N \\;\\text{layers} \\\\\n",
    "&\\downarrow \\\\\n",
    "&[\\text{CLS}] \\;\\text{output} \\;\\rightarrow\\; \\text{Pooler} \\;\\rightarrow\\; \\text{Classification} \\\\\n",
    "&\\text{All tokens} \\;\\rightarrow\\; \\text{Token-level predictions (MLM, NER, QA, etc.)}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "\n",
    "### Key Components:\n",
    "1. **Embedding Layer**: Token + Position + Segment\n",
    "2. **Encoder Stack**: 12 layers for Base, 24 for Large\n",
    "3. **Pooler**: Dense layer on [CLS] for classification\n",
    "4. **MLM Head**: Predicts masked tokens\n",
    "5. **NSP Head**: Predicts if sentence B follows A\n",
    "\n",
    "### Model Sizes:\n",
    "- **BERT-Base**: 110M parameters (~440MB)\n",
    "- **BERT-Large**: 340M parameters (~1.3GB)\n",
    "- **BERT-Tiny** (for testing): 4.4M parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9278293b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Creating BERT models...\n",
      "\n",
      " BERT-Tiny created!\n",
      "   Parameters: 4,385,920\n",
      "   Size: 17.5MB\n",
      "\n",
      " BERT-Base created!\n",
      "   Parameters: 109,482,240\n",
      "   Size: 437.9MB (0.44GB)\n",
      "\n",
      "  Forward pass test:\n",
      "   Input IDs: torch.Size([2, 20])\n",
      "   Sequence output: torch.Size([2, 20, 768])\n",
      "   Pooled output (CLS): torch.Size([2, 768])\n",
      "   Attention layers: 12\n",
      " GPU Memory - Allocated: 1.23GB, Cached: 1.31GB, Total: 4.2GB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1.234421248, 1.31072, 4.227465216)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class BERTModel(nn.Module):\n",
    "    \"\"\"\n",
    "    Complete BERT model implementation.\n",
    "    \n",
    "    Args:\n",
    "        vocab_size (int): Vocabulary size\n",
    "        d_model (int): Model dimension\n",
    "        n_heads (int): Number of attention heads\n",
    "        n_layers (int): Number of encoder layers\n",
    "        d_ff (int): Feed-forward dimension\n",
    "        max_seq_len (int): Maximum sequence length\n",
    "        dropout (float): Dropout probability\n",
    "    \"\"\"\n",
    "    def __init__(self, vocab_size, d_model, n_heads, n_layers, d_ff=None, max_seq_len=512, dropout=0.1):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.d_model = d_model\n",
    "        self.max_seq_len = max_seq_len\n",
    "        \n",
    "        # Embeddings\n",
    "        self.embedding = BERTEmbedding(vocab_size, d_model, max_seq_len, dropout)\n",
    "        \n",
    "        # Transformer encoder blocks\n",
    "        self.encoder_blocks = nn.ModuleList([\n",
    "            TransformerEncoderBlock(d_model, n_heads, d_ff, dropout)\n",
    "            for _ in range(n_layers)\n",
    "        ])\n",
    "        \n",
    "        # Pooler for [CLS] token (used in classification tasks)\n",
    "        self.pooler = nn.Linear(d_model, d_model)\n",
    "        self.pooler_activation = nn.Tanh()\n",
    "        \n",
    "        # Initialize weights\n",
    "        self._init_weights()\n",
    "        \n",
    "    def _init_weights(self):\n",
    "        \"\"\"Initialize pooler weights.\"\"\"\n",
    "        nn.init.normal_(self.pooler.weight, mean=0, std=0.02)\n",
    "        nn.init.zeros_(self.pooler.bias)\n",
    "        \n",
    "    def forward(self, input_ids, segment_ids=None, attention_mask=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            input_ids: (batch_size, seq_len)\n",
    "            segment_ids: (batch_size, seq_len) - optional\n",
    "            attention_mask: (batch_size, seq_len) - optional\n",
    "        \n",
    "        Returns:\n",
    "            sequence_output: (batch_size, seq_len, d_model)\n",
    "            pooled_output: (batch_size, d_model)\n",
    "        \"\"\"\n",
    "        batch_size, seq_len = input_ids.shape\n",
    "        \n",
    "        # Create attention mask if not provided\n",
    "        if attention_mask is None:\n",
    "            attention_mask = torch.ones_like(input_ids)\n",
    "        \n",
    "        # Embeddings\n",
    "        x = self.embedding(input_ids, segment_ids)\n",
    "        \n",
    "        # Pass through encoder blocks\n",
    "        attention_weights_list = []\n",
    "        for encoder_block in self.encoder_blocks:\n",
    "            x, attn_weights = encoder_block(x, attention_mask)\n",
    "            attention_weights_list.append(attn_weights)\n",
    "        \n",
    "        # Sequence output (all tokens)\n",
    "        sequence_output = x\n",
    "        \n",
    "        # Pooled output (only [CLS] token)\n",
    "        cls_output = x[:, 0, :]  # Take first token ([CLS])\n",
    "        pooled_output = self.pooler_activation(self.pooler(cls_output))\n",
    "        \n",
    "        return sequence_output, pooled_output, attention_weights_list\n",
    "\n",
    "# BERT-Base configuration (fits well on T4)\n",
    "config_base = {\n",
    "    'vocab_size': 30522,\n",
    "    'd_model': 768,\n",
    "    'n_heads': 12,\n",
    "    'n_layers': 12,\n",
    "    'd_ff': 3072,\n",
    "    'max_seq_len': 512,\n",
    "    'dropout': 0.1\n",
    "}\n",
    "\n",
    "# Create BERT-Tiny for quick testing\n",
    "config_tiny = {\n",
    "    'vocab_size': 30522,\n",
    "    'd_model': 128,\n",
    "    'n_heads': 2,\n",
    "    'n_layers': 2,\n",
    "    'd_ff': 512,\n",
    "    'max_seq_len': 512,\n",
    "    'dropout': 0.1\n",
    "}\n",
    "\n",
    "print(\" Creating BERT models...\")\n",
    "\n",
    "# Create BERT-Tiny for testing\n",
    "bert_tiny = BERTModel(**config_tiny).to(device)\n",
    "tiny_stats = get_model_size(bert_tiny)\n",
    "print(f\"\\n BERT-Tiny created!\")\n",
    "print(f\"   Parameters: {tiny_stats['parameters']:,}\")\n",
    "print(f\"   Size: {tiny_stats['size_mb']:.1f}MB\")\n",
    "\n",
    "# Create BERT-Base (comment out if memory constrained)\n",
    "bert_base = BERTModel(**config_base).to(device)\n",
    "base_stats = get_model_size(bert_base)\n",
    "print(f\"\\n BERT-Base created!\")\n",
    "print(f\"   Parameters: {base_stats['parameters']:,}\")\n",
    "print(f\"   Size: {base_stats['size_mb']:.1f}MB ({base_stats['size_gb']:.2f}GB)\")\n",
    "\n",
    "# Test forward pass\n",
    "test_input_ids = torch.randint(100, 30000, (2, 20)).to(device)\n",
    "test_segment_ids = torch.cat([\n",
    "    torch.zeros(2, 10, dtype=torch.long),\n",
    "    torch.ones(2, 10, dtype=torch.long)\n",
    "], dim=1).to(device)\n",
    "test_mask = torch.ones(2, 20).to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    seq_output, pooled_output, attn_weights = bert_base(\n",
    "        test_input_ids, test_segment_ids, test_mask\n",
    "    )\n",
    "\n",
    "print(f\"\\n  Forward pass test:\")\n",
    "print(f\"   Input IDs: {test_input_ids.shape}\")\n",
    "print(f\"   Sequence output: {seq_output.shape}\")\n",
    "print(f\"   Pooled output (CLS): {pooled_output.shape}\")\n",
    "print(f\"   Attention layers: {len(attn_weights)}\")\n",
    "\n",
    "# Memory check\n",
    "check_gpu_memory()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e01af679",
   "metadata": {},
   "source": [
    "## Pre-training Tasks\n",
    "\n",
    "BERT is pre-trained on two tasks simultaneously:\n",
    "\n",
    "### 1. Masked Language Modeling (MLM)\n",
    "- **Goal**: Predict masked tokens using bidirectional context\n",
    "- **Process**: Randomly mask 15% of tokens\n",
    "  - 80% replaced with [MASK]\n",
    "  - 10% replaced with random token\n",
    "  - 10% kept unchanged\n",
    "- **Why this strategy?**: Prevents model from learning that [MASK] only appears during training\n",
    "\n",
    "### 2. Next Sentence Prediction (NSP)\n",
    "- **Goal**: Predict if sentence B follows sentence A\n",
    "- **Process**: 50% positive pairs, 50% negative pairs\n",
    "- **Use case**: Improves performance on QA and NLI tasks\n",
    "\n",
    "### Mathematical Formulation:\n",
    "\n",
    "### üßÆ BERT Training Objectives\n",
    "\n",
    "**Masked Language Modeling (MLM) Loss:**\n",
    "\n",
    "$$\n",
    "\\mathcal{L}_{\\text{MLM}} = -\\frac{1}{|M|} \\sum_{i \\in M} \\log P\\big(x_i \\mid x_{\\setminus M}\\big)\n",
    "$$\n",
    "\n",
    "where  \n",
    "- $ M $ = set of masked token positions  \n",
    "- $ x_i $ = true token at position $ i $ \n",
    "- $ x_{\\setminus M} $ = input sequence with masked tokens  \n",
    "\n",
    "---\n",
    "\n",
    "**Next Sentence Prediction (NSP) Loss:**\n",
    "\n",
    "$$\n",
    "\\mathcal{L}_{\\text{NSP}} = - \\log P(\\text{IsNext} \\mid h_{\\text{[CLS]}})\n",
    "$$\n",
    "\n",
    "where  \n",
    "- $ h_{\\text{[CLS]}} $ = representation of the [CLS] token from the final encoder layer  \n",
    "\n",
    "---\n",
    "\n",
    "**Total Training Loss:**\n",
    "\n",
    "$$\n",
    "\\mathcal{L}_{\\text{total}} = \\mathcal{L}_{\\text{MLM}} + \\mathcal{L}_{\\text{NSP}}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f1cfa6f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   BERT Pre-training Model created!\n",
      "   Total parameters: 133,547,324\n",
      "\n",
      "   MLM logits: torch.Size([2, 20, 30522])\n",
      "   NSP logits: torch.Size([2, 2])\n"
     ]
    }
   ],
   "source": [
    "class BERTForPreTraining(nn.Module):\n",
    "    \"\"\"\n",
    "    BERT with MLM and NSP heads for pre-training.\n",
    "    \n",
    "    Args:\n",
    "        bert_model: Base BERT model\n",
    "        vocab_size: Vocabulary size\n",
    "    \"\"\"\n",
    "    def __init__(self, bert_model, vocab_size):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.bert = bert_model\n",
    "        d_model = bert_model.d_model\n",
    "        \n",
    "        # MLM Head (predicts masked tokens)\n",
    "        self.mlm_head = nn.Sequential(\n",
    "            nn.Linear(d_model, d_model),\n",
    "            nn.GELU(),\n",
    "            nn.LayerNorm(d_model, eps=1e-12),\n",
    "            nn.Linear(d_model, vocab_size)\n",
    "        )\n",
    "        \n",
    "        # NSP Head (predicts if sentence B follows A)\n",
    "        self.nsp_head = nn.Linear(d_model, 2)  # Binary classification\n",
    "        \n",
    "        # Initialize weights\n",
    "        self._init_weights()\n",
    "        \n",
    "    def _init_weights(self):\n",
    "        \"\"\"Initialize head weights.\"\"\"\n",
    "        for module in self.mlm_head:\n",
    "            if isinstance(module, nn.Linear):\n",
    "                nn.init.normal_(module.weight, mean=0, std=0.02)\n",
    "                nn.init.zeros_(module.bias)\n",
    "        \n",
    "        nn.init.normal_(self.nsp_head.weight, mean=0, std=0.02)\n",
    "        nn.init.zeros_(self.nsp_head.bias)\n",
    "        \n",
    "    def forward(self, input_ids, segment_ids=None, attention_mask=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            input_ids: (batch_size, seq_len)\n",
    "            segment_ids: (batch_size, seq_len)\n",
    "            attention_mask: (batch_size, seq_len)\n",
    "        \n",
    "        Returns:\n",
    "            mlm_logits: (batch_size, seq_len, vocab_size)\n",
    "            nsp_logits: (batch_size, 2)\n",
    "        \"\"\"\n",
    "        # Get BERT outputs\n",
    "        sequence_output, pooled_output, _ = self.bert(\n",
    "            input_ids, segment_ids, attention_mask\n",
    "        )\n",
    "        \n",
    "        # MLM predictions for all tokens\n",
    "        mlm_logits = self.mlm_head(sequence_output)\n",
    "        \n",
    "        # NSP prediction from [CLS] token\n",
    "        nsp_logits = self.nsp_head(pooled_output)\n",
    "        \n",
    "        return mlm_logits, nsp_logits\n",
    "\n",
    "# Create pre-training model\n",
    "bert_pretrain = BERTForPreTraining(bert_base, config_base['vocab_size']).to(device)\n",
    "\n",
    "print(\"   BERT Pre-training Model created!\")\n",
    "print(f\"   Total parameters: {sum(p.numel() for p in bert_pretrain.parameters()):,}\")\n",
    "\n",
    "# Test pre-training forward pass\n",
    "with torch.no_grad():\n",
    "    mlm_logits, nsp_logits = bert_pretrain(\n",
    "        test_input_ids, test_segment_ids, test_mask\n",
    "    )\n",
    "\n",
    "print(f\"\\n   MLM logits: {mlm_logits.shape}\")\n",
    "print(f\"   NSP logits: {nsp_logits.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee9f5ff0",
   "metadata": {},
   "source": [
    "## Masked Language Modeling (MLM) Implementation\n",
    "\n",
    "Let's implement the masking strategy and training for MLM.\n",
    "\n",
    "### Masking Strategy:\n",
    "For each selected token:\n",
    "- 80% chance: Replace with [MASK] token\n",
    "- 10% chance: Replace with random token\n",
    "- 10% chance: Keep original token\n",
    "\n",
    "### Why this complexity?\n",
    "- **[MASK] doesn't appear in fine-tuning**: Model must learn robust representations\n",
    "- **Random tokens**: Prevents overfitting to specific patterns\n",
    "- **Original tokens**: Model learns to refine representations\n",
    "\n",
    "### Special Tokens:\n",
    "- [PAD] = 0\n",
    "- [CLS] = 101\n",
    "- [SEP] = 102\n",
    "- [MASK] = 103"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2c593777",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  MLM Masking Test:\n",
      "   Original tokens: [101, 19749, 9834, 23774, 27982, 15580, 23098, 12021, 13866, 26658, 102, 19625, 948, 1104, 14391]\n",
      "   Masked tokens:   [101, 103, 9834, 23774, 103, 15580, 23098, 12021, 13866, 26658, 102, 19625, 948, 1104, 14391]\n",
      "   Masked positions: [4, 1]\n",
      "   Number masked: 2 / 20 (10.0%)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MLMDataset:\n",
    "    \"\"\"\n",
    "    Creates MLM training data from raw token sequences.\n",
    "    \"\"\"\n",
    "    def __init__(self, vocab_size, mask_prob=0.15, mask_token_id=103):\n",
    "        self.vocab_size = vocab_size\n",
    "        self.mask_prob = mask_prob\n",
    "        self.mask_token_id = mask_token_id\n",
    "        self.special_tokens = {0, 101, 102, 103}  # [PAD], [CLS], [SEP], [MASK]\n",
    "        \n",
    "    def create_masked_lm_predictions(self, tokens):\n",
    "        \"\"\"\n",
    "        Create masked LM predictions for a sequence.\n",
    "        \n",
    "        Args:\n",
    "            tokens: (seq_len,) tensor of token IDs\n",
    "        \n",
    "        Returns:\n",
    "            masked_tokens: tokens with masking applied\n",
    "            masked_positions: positions that were masked\n",
    "            masked_labels: original tokens at masked positions\n",
    "        \"\"\"\n",
    "        seq_len = tokens.size(0)\n",
    "        masked_tokens = tokens.clone()\n",
    "        \n",
    "        # Don't mask special tokens\n",
    "        candidate_positions = [i for i in range(seq_len) \n",
    "                              if tokens[i].item() not in self.special_tokens]\n",
    "        \n",
    "        # Select 15% of positions to mask\n",
    "        n_masked = max(1, int(len(candidate_positions) * self.mask_prob))\n",
    "        masked_positions = random.sample(candidate_positions, n_masked)\n",
    "        \n",
    "        masked_labels = torch.zeros(seq_len, dtype=torch.long) - 100  # -100 = ignore in loss\n",
    "        \n",
    "        for pos in masked_positions:\n",
    "            masked_labels[pos] = tokens[pos].item()\n",
    "            \n",
    "            prob = random.random()\n",
    "            if prob < 0.8:\n",
    "                # 80% of the time, replace with [MASK]\n",
    "                masked_tokens[pos] = self.mask_token_id\n",
    "            elif prob < 0.9:\n",
    "                # 10% of the time, replace with random token\n",
    "                masked_tokens[pos] = random.randint(1, self.vocab_size - 1)\n",
    "            # else: 10% of the time, keep original\n",
    "        \n",
    "        return masked_tokens, torch.tensor(masked_positions), masked_labels\n",
    "\n",
    "# Test MLM masking\n",
    "mlm_dataset = MLMDataset(config_base['vocab_size'])\n",
    "\n",
    "sample_tokens = torch.randint(104, 30000, (20,))\n",
    "sample_tokens[0] = 101  # [CLS]\n",
    "sample_tokens[10] = 102  # [SEP]\n",
    "\n",
    "masked_tokens, masked_pos, masked_labels = mlm_dataset.create_masked_lm_predictions(sample_tokens)\n",
    "\n",
    "print(\"  MLM Masking Test:\")\n",
    "print(f\"   Original tokens: {sample_tokens[:15].tolist()}\")\n",
    "print(f\"   Masked tokens:   {masked_tokens[:15].tolist()}\")\n",
    "print(f\"   Masked positions: {masked_pos.tolist()}\")\n",
    "print(f\"   Number masked: {len(masked_pos)} / {len(sample_tokens)} ({len(masked_pos)/len(sample_tokens)*100:.1f}%)\")\n",
    "\n",
    "# Visualize masking\n",
    "fig, axes = plt.subplots(2, 1, figsize=(12, 4))\n",
    "\n",
    "axes[0].bar(range(len(sample_tokens)), sample_tokens.numpy(), color='blue', alpha=0.6)\n",
    "axes[0].set_title('Original Tokens')\n",
    "axes[0].set_ylabel('Token ID')\n",
    "\n",
    "axes[1].bar(range(len(masked_tokens)), masked_tokens.numpy(), color='orange', alpha=0.6)\n",
    "for pos in masked_pos:\n",
    "    axes[1].axvline(x=pos, color='red', linestyle='--', alpha=0.5)\n",
    "axes[1].set_title('Masked Tokens (red lines = masked positions)')\n",
    "axes[1].set_xlabel('Position')\n",
    "axes[1].set_ylabel('Token ID')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01ac6488",
   "metadata": {},
   "source": [
    "## Training Loop for Pre-training\n",
    "\n",
    "Let's implement a training loop for BERT pre-training with both MLM and NSP tasks.\n",
    "\n",
    "### Training Strategy:\n",
    "1. **MLM Loss**: Cross-entropy on masked positions only\n",
    "2. **NSP Loss**: Binary cross-entropy on sentence pair classification\n",
    "3. **Total Loss**: Sum of both losses\n",
    "4. **Optimization**: AdamW with learning rate warmup\n",
    "\n",
    "### üî∫ Learning Rate Schedule (Linear Warmup + Decay)\n",
    "\n",
    "$$\n",
    "\\text{lr}(t) = \\text{lr}_{\\text{max}} \\times \n",
    "\\min \\left( \n",
    "\\frac{t}{\\text{warmup}}, \\;\n",
    "\\frac{\\text{total\\_steps} - t}{\\text{total\\_steps} - \\text{warmup}}\n",
    "\\right)\n",
    "$$\n",
    "\n",
    "where  \n",
    "- $ t $ = current training step  \n",
    "- $ \\text{warmup} $ = number of warmup steps  \n",
    "- $ \\text{total\\_steps} $ = total training steps  \n",
    "- $ \\text{lr}_{\\text{max}} $ = peak learning rate  \n",
    "\n",
    "---\n",
    "\n",
    "**Explanation:**\n",
    "- During the **warmup phase** $ (t < \\text{warmup}) $, learning rate increases linearly from 0 ‚Üí $ \\text{lr}_{\\text{max}} $.  \n",
    "- After warmup, it **decays linearly** back toward 0 over the remaining steps.  \n",
    "- This schedule helps stabilize early training and prevents divergence in large-batch optimization (common in BERT pretraining).\n",
    "\n",
    "\n",
    "### Hyperparameters (BERT paper):\n",
    "- Batch size: 256 sequences\n",
    "- Max seq length: 512 tokens\n",
    "- Learning rate: 1e-4\n",
    "- Warmup steps: 10,000\n",
    "- Training steps: 1,000,000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b27a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.cuda.amp import autocast, GradScaler\n",
    "\n",
    "def train_bert_pretrain(model, dataloader, num_steps=100, learning_rate=1e-4, warmup_steps=10):\n",
    "    \"\"\"\n",
    "    Training loop for BERT pre-training.\n",
    "    \n",
    "    Args:\n",
    "        model: BERT pre-training model\n",
    "        dataloader: Training data loader\n",
    "        num_steps: Number of training steps\n",
    "        learning_rate: Peak learning rate\n",
    "        warmup_steps: Number of warmup steps\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate, \n",
    "                                   betas=(0.9, 0.999), weight_decay=0.01)\n",
    "    scaler = GradScaler()  # For mixed precision\n",
    "    \n",
    "    # Loss functions\n",
    "    mlm_criterion = nn.CrossEntropyLoss(ignore_index=-100)  # Ignore non-masked tokens\n",
    "    nsp_criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    losses_mlm = []\n",
    "    losses_nsp = []\n",
    "    losses_total = []\n",
    "    \n",
    "    step = 0\n",
    "    print(\"  Starting BERT pre-training...\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    for epoch in range(100):  # Arbitrary large number\n",
    "        for batch_idx, batch in enumerate(dataloader):\n",
    "            if step >= num_steps:\n",
    "                break\n",
    "                \n",
    "            # Learning rate warmup\n",
    "            if step < warmup_steps:\n",
    "                lr_scale = (step + 1) / warmup_steps\n",
    "            else:\n",
    "                lr_scale = 1.0\n",
    "            \n",
    "            for param_group in optimizer.param_groups:\n",
    "                param_group['lr'] = learning_rate * lr_scale\n",
    "            \n",
    "            # Unpack batch\n",
    "            input_ids = batch[0].to(device)\n",
    "            segment_ids = batch[1].to(device)\n",
    "            attention_mask = batch[2].to(device)\n",
    "            mlm_labels = batch[3].to(device)\n",
    "            nsp_labels = batch[4].to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Mixed precision forward pass\n",
    "            with autocast():\n",
    "                mlm_logits, nsp_logits = model(input_ids, segment_ids, attention_mask)\n",
    "                \n",
    "                # Compute losses\n",
    "                mlm_loss = mlm_criterion(mlm_logits.view(-1, mlm_logits.size(-1)), \n",
    "                                         mlm_labels.view(-1))\n",
    "                nsp_loss = nsp_criterion(nsp_logits, nsp_labels)\n",
    "                total_loss = mlm_loss + nsp_loss\n",
    "            \n",
    "            # Backward pass with gradient scaling\n",
    "            scaler.scale(total_loss).backward()\n",
    "            scaler.unscale_(optimizer)\n",
    "            \n",
    "            # Gradient clipping\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            \n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            \n",
    "            # Record losses\n",
    "            losses_mlm.append(mlm_loss.item())\n",
    "            losses_nsp.append(nsp_loss.item())\n",
    "            losses_total.append(total_loss.item())\n",
    "            \n",
    "            if step % 10 == 0:\n",
    "                print(f\"Step {step:3d} | LR: {optimizer.param_groups[0]['lr']:.6f} | \"\n",
    "                      f\"MLM: {mlm_loss.item():.4f} | NSP: {nsp_loss.item():.4f} | \"\n",
    "                      f\"Total: {total_loss.item():.4f}\")\n",
    "            \n",
    "            step += 1\n",
    "            \n",
    "        if step >= num_steps:\n",
    "            break\n",
    "    \n",
    "    print(\"=\" * 60)\n",
    "    print(f\"   Training completed!\")\n",
    "    print(f\"   Final MLM loss: {losses_mlm[-1]:.4f}\")\n",
    "    print(f\"   Final NSP loss: {losses_nsp[-1]:.4f}\")\n",
    "    print(f\"   Final Total loss: {losses_total[-1]:.4f}\")\n",
    "    \n",
    "    return losses_mlm, losses_nsp, losses_total\n",
    "\n",
    "# Create dummy pre-training dataset\n",
    "def create_pretraining_data(vocab_size, num_samples=100, seq_len=64):\n",
    "    \"\"\"Create dummy pre-training data.\"\"\"\n",
    "    mlm_dataset_helper = MLMDataset(vocab_size)\n",
    "    \n",
    "    input_ids_list = []\n",
    "    segment_ids_list = []\n",
    "    attention_mask_list = []\n",
    "    mlm_labels_list = []\n",
    "    nsp_labels_list = []\n",
    "    \n",
    "    for _ in range(num_samples):\n",
    "        # Generate random sequence\n",
    "        seq = torch.randint(104, vocab_size, (seq_len,))\n",
    "        seq[0] = 101  # [CLS]\n",
    "        \n",
    "        # Random split for two sentences\n",
    "        split_point = random.randint(seq_len // 3, 2 * seq_len // 3)\n",
    "        seq[split_point] = 102  # [SEP]\n",
    "        \n",
    "        # Segment IDs\n",
    "        segment_ids = torch.cat([\n",
    "            torch.zeros(split_point + 1, dtype=torch.long),\n",
    "            torch.ones(seq_len - split_point - 1, dtype=torch.long)\n",
    "        ])\n",
    "        \n",
    "        # Attention mask (all 1s for this dummy data)\n",
    "        attention_mask = torch.ones(seq_len)\n",
    "        \n",
    "        # Apply MLM masking\n",
    "        masked_seq, _, mlm_labels = mlm_dataset_helper.create_masked_lm_predictions(seq)\n",
    "        \n",
    "        # NSP label (random for dummy data)\n",
    "        nsp_label = random.randint(0, 1)\n",
    "        \n",
    "        input_ids_list.append(masked_seq)\n",
    "        segment_ids_list.append(segment_ids)\n",
    "        attention_mask_list.append(attention_mask)\n",
    "        mlm_labels_list.append(mlm_labels)\n",
    "        nsp_labels_list.append(nsp_label)\n",
    "    \n",
    "    return TensorDataset(\n",
    "        torch.stack(input_ids_list),\n",
    "        torch.stack(segment_ids_list),\n",
    "        torch.stack(attention_mask_list),\n",
    "        torch.stack(mlm_labels_list),\n",
    "        torch.tensor(nsp_labels_list, dtype=torch.long)\n",
    "    )\n",
    "\n",
    "# Create training data and dataloader\n",
    "print(\"  Creating pre-training dataset...\")\n",
    "pretrain_dataset = create_pretraining_data(config_tiny['vocab_size'], num_samples=200, seq_len=64)\n",
    "pretrain_loader = DataLoader(pretrain_dataset, batch_size=8, shuffle=True)\n",
    "\n",
    "print(f\"   Dataset size: {len(pretrain_dataset)} samples\")\n",
    "print(f\"   Batch size: 8\")\n",
    "\n",
    "# Train BERT-Tiny for demonstration\n",
    "bert_tiny_pretrain = BERTForPreTraining(bert_tiny, config_tiny['vocab_size']).to(device)\n",
    "\n",
    "losses_mlm, losses_nsp, losses_total = train_bert_pretrain(\n",
    "    bert_tiny_pretrain, \n",
    "    pretrain_loader, \n",
    "    num_steps=50,\n",
    "    learning_rate=1e-4,\n",
    "    warmup_steps=5\n",
    ")\n",
    "\n",
    "# Plot training curves\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "axes[0].plot(losses_mlm, 'b-', linewidth=2)\n",
    "axes[0].set_title('MLM Loss')\n",
    "axes[0].set_xlabel('Step')\n",
    "axes[0].set_ylabel('Loss')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "axes[1].plot(losses_nsp, 'g-', linewidth=2)\n",
    "axes[1].set_title('NSP Loss')\n",
    "axes[1].set_xlabel('Step')\n",
    "axes[1].set_ylabel('Loss')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "axes[2].plot(losses_total, 'r-', linewidth=2)\n",
    "axes[2].set_title('Total Loss')\n",
    "axes[2].set_xlabel('Step')\n",
    "axes[2].set_ylabel('Loss')\n",
    "axes[2].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "check_gpu_memory()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a844dec3",
   "metadata": {},
   "source": [
    "## Fine-tuning for Downstream Tasks\n",
    "\n",
    "After pre-training, BERT can be fine-tuned for specific tasks by adding task-specific heads.\n",
    "\n",
    "### Common Fine-tuning Tasks:\n",
    "\n",
    "1. **Sequence Classification** (Sentiment, Topic, etc.)\n",
    "   - Use [CLS] token representation\n",
    "   - Add linear classifier on top\n",
    "\n",
    "2. **Token Classification** (NER, POS tagging)\n",
    "   - Use all token representations\n",
    "   - Add linear classifier for each token\n",
    "\n",
    "3. **Question Answering** (SQuAD)\n",
    "   - Predict start and end positions\n",
    "   - Two separate linear layers\n",
    "\n",
    "4. **Sentence Pair Classification** (NLI, Paraphrase)\n",
    "   - Use [CLS] token representation\n",
    "   - Input format: [CLS] Sentence A [SEP] Sentence B [SEP]\n",
    "\n",
    "### Fine-tuning vs Pre-training:\n",
    "- **Learning rate**: Much smaller (2e-5 to 5e-5)\n",
    "- **Epochs**: Few (2-4 typically)\n",
    "- **Batch size**: Smaller (16-32)\n",
    "- **All parameters**: Fine-tune entire model, not just head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3b964748",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fine-tuning Models created!\n",
      "\n",
      "   Sequence Classification:\n",
      "      Parameters: 4,386,565\n",
      "\n",
      "   Token Classification:\n",
      "      Parameters: 4,387,081\n",
      "\n",
      "   Sequence classification output: torch.Size([4, 5])\n",
      "   Token classification output: torch.Size([4, 32, 9])\n"
     ]
    }
   ],
   "source": [
    "class BERTForSequenceClassification(nn.Module):\n",
    "    \"\"\"\n",
    "    BERT for sequence classification (sentiment, topic, etc.)\n",
    "    \n",
    "    Args:\n",
    "        bert_model: Pre-trained BERT model\n",
    "        num_classes: Number of classes\n",
    "        dropout: Dropout probability\n",
    "    \"\"\"\n",
    "    def __init__(self, bert_model, num_classes, dropout=0.1):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.bert = bert_model\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.classifier = nn.Linear(bert_model.d_model, num_classes)\n",
    "        \n",
    "        # Initialize classifier\n",
    "        nn.init.normal_(self.classifier.weight, mean=0, std=0.02)\n",
    "        nn.init.zeros_(self.classifier.bias)\n",
    "        \n",
    "    def forward(self, input_ids, segment_ids=None, attention_mask=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            input_ids: (batch_size, seq_len)\n",
    "            segment_ids: (batch_size, seq_len)\n",
    "            attention_mask: (batch_size, seq_len)\n",
    "        \n",
    "        Returns:\n",
    "            logits: (batch_size, num_classes)\n",
    "        \"\"\"\n",
    "        # Get BERT outputs\n",
    "        _, pooled_output, _ = self.bert(input_ids, segment_ids, attention_mask)\n",
    "        \n",
    "        # Apply dropout and classifier\n",
    "        pooled_output = self.dropout(pooled_output)\n",
    "        logits = self.classifier(pooled_output)\n",
    "        \n",
    "        return logits\n",
    "\n",
    "class BERTForTokenClassification(nn.Module):\n",
    "    \"\"\"\n",
    "    BERT for token classification (NER, POS tagging, etc.)\n",
    "    \n",
    "    Args:\n",
    "        bert_model: Pre-trained BERT model\n",
    "        num_labels: Number of labels per token\n",
    "        dropout: Dropout probability\n",
    "    \"\"\"\n",
    "    def __init__(self, bert_model, num_labels, dropout=0.1):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.bert = bert_model\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.classifier = nn.Linear(bert_model.d_model, num_labels)\n",
    "        \n",
    "        # Initialize classifier\n",
    "        nn.init.normal_(self.classifier.weight, mean=0, std=0.02)\n",
    "        nn.init.zeros_(self.classifier.bias)\n",
    "        \n",
    "    def forward(self, input_ids, segment_ids=None, attention_mask=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            input_ids: (batch_size, seq_len)\n",
    "            segment_ids: (batch_size, seq_len)\n",
    "            attention_mask: (batch_size, seq_len)\n",
    "        \n",
    "        Returns:\n",
    "            logits: (batch_size, seq_len, num_labels)\n",
    "        \"\"\"\n",
    "        # Get BERT outputs\n",
    "        sequence_output, _, _ = self.bert(input_ids, segment_ids, attention_mask)\n",
    "        \n",
    "        # Apply dropout and classifier to all tokens\n",
    "        sequence_output = self.dropout(sequence_output)\n",
    "        logits = self.classifier(sequence_output)\n",
    "        \n",
    "        return logits\n",
    "\n",
    "# Create fine-tuning models\n",
    "num_classes = 5  # e.g., 5-way sentiment classification\n",
    "num_labels = 9   # e.g., NER with 9 entity types\n",
    "\n",
    "bert_classifier = BERTForSequenceClassification(bert_tiny, num_classes).to(device)\n",
    "bert_token_classifier = BERTForTokenClassification(bert_tiny, num_labels).to(device)\n",
    "\n",
    "print(\"  Fine-tuning Models created!\")\n",
    "print(f\"\\n   Sequence Classification:\")\n",
    "print(f\"      Parameters: {sum(p.numel() for p in bert_classifier.parameters()):,}\")\n",
    "\n",
    "print(f\"\\n   Token Classification:\")\n",
    "print(f\"      Parameters: {sum(p.numel() for p in bert_token_classifier.parameters()):,}\")\n",
    "\n",
    "# Test fine-tuning forward passes\n",
    "test_input = torch.randint(104, 30000, (4, 32)).to(device)\n",
    "test_mask = torch.ones(4, 32).to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    # Sequence classification\n",
    "    seq_logits = bert_classifier(test_input, attention_mask=test_mask)\n",
    "    print(f\"\\n   Sequence classification output: {seq_logits.shape}\")\n",
    "    \n",
    "    # Token classification\n",
    "    token_logits = bert_token_classifier(test_input, attention_mask=test_mask)\n",
    "    print(f\"   Token classification output: {token_logits.shape}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
